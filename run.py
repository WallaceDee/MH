#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
CBGçˆ¬è™«é¡¹ç›®å¯åŠ¨è„šæœ¬
æä¾›å¤šç§è¿è¡Œæ¨¡å¼
"""

import sys
import os
import argparse

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(project_root, 'src')
sys.path.insert(0, src_path)

def run_basic_spider(max_pages=5):
    """è¿è¡ŒåŸºç¡€çˆ¬è™«"""
    print("å¯åŠ¨åŸºç¡€CBGçˆ¬è™«...")
    try:
        from cbg_spider import CBGSpider
        print("âœ… æˆåŠŸå¯¼å…¥CBGSpider")
    except Exception as e:
        print(f"âŒ å¯¼å…¥CBGSpiderå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    try:
        spider = CBGSpider()
        print("ğŸ”§ CBGçˆ¬è™«åˆå§‹åŒ–å®Œæˆ")
        
        # çˆ¬å–æ•°æ®
        print("å¼€å§‹çˆ¬å–æ•°æ®...")
        spider.crawl_all_pages(max_pages=max_pages,delay_range=[1, 3],use_browser=True)
        print("æ•°æ®çˆ¬å–å®Œæˆ")
        
        # å¯¼å‡ºExcel
        print("\næ­£åœ¨å¯¼å‡ºExcel...")
        excel_file = spider.export_to_excel()
        if excel_file:
            print(f"Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file}")
        else:
            print("âŒ Excelå¯¼å‡ºå¤±è´¥")
        
        # å¯¼å‡ºJSON
        print("\næ­£åœ¨å¯¼å‡ºJSON...")
        json_file = spider.export_to_json(filename=None, pretty=False)
        if json_file:
            print(f"JSONæ–‡ä»¶å·²ç”Ÿæˆ: {json_file}")
        else:
            print("âŒ JSONå¯¼å‡ºå¤±è´¥")
        
        print("âœ… åŸºç¡€çˆ¬è™«å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def run_proxy_spider(max_pages=5):
    """è¿è¡Œå¸¦ä»£ç†çš„çˆ¬è™«"""
    print("ğŸ”„ å¯åŠ¨å¸¦ä»£ç†çš„CBGçˆ¬è™«...")
    from cbg_crawler_with_proxy import EnhancedCBGCrawler
    
    crawler = EnhancedCBGCrawler()
    crawler.start_crawling(max_pages=max_pages)

def run_proxy_manager():
    """è¿è¡Œä»£ç†ç®¡ç†å™¨"""
    print("ğŸ”§ å¯åŠ¨ä»£ç†IPç®¡ç†å™¨...")
    from proxy_source_manager import ProxySourceManager
    
    manager = ProxySourceManager()
    proxies = manager.get_all_proxies()
    manager.save_proxies_to_file(proxies)
    print(f"âœ… è·å–åˆ° {len(proxies)} ä¸ªä»£ç†IP")

def run_tests():
    """è¿è¡Œæµ‹è¯•"""
    print("ğŸ§ª è¿è¡Œé¡¹ç›®æµ‹è¯•...")
    import subprocess
    
    tests_path = os.path.join(project_root, 'tests', 'test_optimized_spider.py')
    subprocess.run([sys.executable, tests_path])

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='CBGçˆ¬è™«é¡¹ç›®å¯åŠ¨å™¨')
    parser.add_argument('mode', choices=['basic', 'proxy', 'proxy-manager', 'test'], 
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--pages', type=int, default=5, 
                       help='çˆ¬å–é¡µæ•° (é»˜è®¤: 5)')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ® CBGæ™ºèƒ½çˆ¬è™«ç³»ç»Ÿ v1.0.0")
    print("=" * 60)
    
    try:
        if args.mode == 'basic':
            run_basic_spider(args.pages)
        elif args.mode == 'proxy':
            run_proxy_spider(args.pages)
        elif args.mode == 'proxy-manager':
            run_proxy_manager()
        elif args.mode == 'test':
            run_tests()
            
        print("\nâœ… ä»»åŠ¡å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("=" * 60)

if __name__ == "__main__":
    main() 