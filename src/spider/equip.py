#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¢¦å¹»è¥¿æ¸¸è—å®é˜è£…å¤‡çˆ¬è™«æ¨¡å—
ä¸“é—¨ç”¨äºçˆ¬å–è£…å¤‡æ•°æ®
"""

import os
import sys
import json
import time
import random
import logging
from datetime import datetime
from urllib.parse import urlencode
import asyncio
import pandas as pd
from playwright.async_api import async_playwright
import re
import threading
from concurrent.futures import ThreadPoolExecutor

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
from src.utils.project_path import get_project_root
project_root = get_project_root()
sys.path.insert(0, project_root)

from src.tools.setup_requests_session import setup_session
from src.database import db
from src.models.equipment import Equipment
from src.tools.search_form_helper import (
    get_equip_search_params_sync,
    get_lingshi_search_params_sync,
    get_pet_equip_search_params_sync,
    get_equip_search_params_async,
    get_lingshi_search_params_async,
    get_pet_equip_search_params_async,
)
from src.utils.cookie_manager import (
    setup_session_with_cookies, 
    get_playwright_cookies_for_context,
    verify_cookie_validity
)

# å¯¼å…¥ç‰¹å¾æå–å™¨
from src.evaluator.feature_extractor.lingshi_feature_extractor import LingshiFeatureExtractor
from src.evaluator.feature_extractor.pet_equip_feature_extractor import PetEquipFeatureExtractor
from src.evaluator.feature_extractor.equip_feature_extractor import EquipFeatureExtractor

# å¯¼å…¥è£…å¤‡ç±»å‹å¸¸é‡
from src.evaluator.constants.equipment_types import LINGSHI_KINDIDS, PET_EQUIP_KINDID,WEAPON_KINDIDS,ARMOR_KINDIDS

class CBGEquipSpider:
    def __init__(self):
        self.session = setup_session()
        self.base_url = 'https://xyq.cbg.163.com/cgi-bin/recommend.py'
        self.output_dir = self.create_output_dir()
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        self.lingshi_feature_extractor = LingshiFeatureExtractor()
        self.pet_equip_feature_extractor = PetEquipFeatureExtractor()
        self.equip_feature_extractor = EquipFeatureExtractor()
        # é…ç½®ä¸“ç”¨çš„æ—¥å¿—å™¨ï¼Œé¿å…ä¸å…¶ä»–æ¨¡å—å†²çª
        self.logger = self._setup_logger()
        
        # åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
        self.setup_session()
        self.retry_attempts = 1
        
        # åˆå§‹åŒ–çº¿ç¨‹æ± ï¼ˆç”¨äºå¼‚æ­¥æ•°æ®åº“æ“ä½œï¼‰
        self._executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix='EquipDB-')
        self.logger.info("çº¿ç¨‹æ± åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å¹¶å‘æ•°: 3")

    def _setup_logger(self):
        """è®¾ç½®ä¸“ç”¨çš„æ—¥å¿—å™¨"""
        # åˆ›å»ºä¸“ç”¨çš„æ—¥å¿—å™¨
        logger = logging.getLogger(f'CBGEquipSpider_{id(self)}')
        logger.setLevel(logging.INFO)
        
        # æ¸…é™¤å¯èƒ½å­˜åœ¨çš„å¤„ç†å™¨ï¼Œé¿å…é‡å¤æ—¥å¿—
        if logger.handlers:
            logger.handlers.clear()
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = os.path.join(self.output_dir, f'cbg_equip_spider_{timestamp}.log')
        file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='w')
        file_handler.setLevel(logging.INFO)
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # åˆ›å»ºæ ¼å¼å™¨
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ å¤„ç†å™¨åˆ°æ—¥å¿—å™¨
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        # é˜²æ­¢æ—¥å¿—ä¼ æ’­åˆ°æ ¹æ—¥å¿—å™¨ï¼Œé¿å…é‡å¤è¾“å‡º
        logger.propagate = False
        
        # æµ‹è¯•æ—¥å¿—å†™å…¥
        logger.info(" CBGè£…å¤‡çˆ¬è™«æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logger.info(f" æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_file}")
        
        return logger

    def create_output_dir(self):
        """åˆ›å»ºè¾“å‡ºç›®å½• - æŒ‰å¹´æœˆåˆ†ç»„"""
        current_date = datetime.now()
        year_month = current_date.strftime('%Y%m')  # 202506
        output_dir = os.path.join('output', year_month)
        os.makedirs(output_dir, exist_ok=True)
        return output_dir
    
    def setup_session(self):
        """è®¾ç½®è¯·æ±‚ä¼šè¯"""
        # ä½¿ç”¨ç»Ÿä¸€çš„Cookieç®¡ç†
        setup_session_with_cookies(
            self.session, 
            referer='https://xyq.cbg.163.com/cgi-bin/xyq_overall_search.py',
            logger=self.logger
        )
    

    def parse_jsonp_response(self, text):
        """è§£æJSONPå“åº”ï¼Œæå–è£…å¤‡æ•°æ®"""
        try:
            # æå–JSONéƒ¨åˆ†
            start = text.find('(') + 1
            end = text.rfind(')')
            if start <= 0 or end <= 0:
                self.logger.error("å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONPæ ¼å¼")
                return None
                
            json_str = text[start:end]
            data = json.loads(json_str)
            
            if not isinstance(data, dict):
                self.logger.error("è§£æJSONPå“åº”å¤±è´¥ï¼šå“åº”ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡")
                return None

            equip_list = data.get('equip_list', [])
            
            if not equip_list:
                self.logger.warning(text)
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è£…å¤‡æ•°æ®")
                return []
                
            equipments = []
            for equip in equip_list:
                try:
                    # ç‰¹å¾æå–ï¼šå½“kindidæ˜¯61ã€62ã€63ã€64æ—¶ï¼Œæå–çµé¥°ç‰¹å¾
                    kindid = equip.get('kindid', 0)
                    extracted_attrs = []
                    
                    if kindid in LINGSHI_KINDIDS:  # çµé¥°è£…å¤‡ç±»å‹
                        try:
                            # ä½¿ç”¨ç‰¹å¾æå–å™¨æå–é™„åŠ å±æ€§
                            added_attrs_features = self.lingshi_feature_extractor._extract_added_attrs_features(equip)
                            extracted_attrs = added_attrs_features.get('attrs', [])
                            
                            if extracted_attrs:
                                self.logger.debug(f"æˆåŠŸæå–çµé¥°è£…å¤‡(kindid:{kindid})çš„é™„åŠ å±æ€§: {len(extracted_attrs)}ä¸ª")
                                # è®°å½•æå–åˆ°çš„å…·ä½“å±æ€§
                                for i, attr in enumerate(extracted_attrs):
                                    self.logger.debug(f"  å±æ€§{i+1}: {attr['attr_type']} +{attr['attr_value']}")
                            else:
                                self.logger.debug(f"çµé¥°è£…å¤‡(kindid:{kindid})æœªæå–åˆ°é™„åŠ å±æ€§")
                                
                        except Exception as e:
                            self.logger.warning(f"æå–çµé¥°è£…å¤‡ç‰¹å¾å¤±è´¥ (kindid:{kindid}): {e}")
                            # å¦‚æœç‰¹å¾æå–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                            extracted_attrs = equip.get('agg_added_attrs', [])
                    else:
                        # éçµé¥°è£…å¤‡ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                        extracted_attrs = equip.get('agg_added_attrs', [])
                    
                    # åˆå§‹åŒ– addon_status å˜é‡
                    addon_status = equip.get('addon_status', '')
                    addon_moli = equip.get('addon_moli', 0)

                    if kindid == PET_EQUIP_KINDID:  # å¬å”¤å…½è£…å¤‡ç±»å‹è¦è§£æå¥—è£…
                        try:
                            # ä½¿ç”¨å¬å”¤å…½è£…å¤‡ç‰¹å¾æå–å™¨è§£æå¥—è£…ä¿¡æ¯
                            desc = equip.get('large_equip_desc', '')
                            if desc:
                                # åˆ›å»ºä¸´æ—¶å­—å…¸æ¥å­˜å‚¨è§£æç»“æœ
                                parsed_data = {}
                                self.pet_equip_feature_extractor._parse_suit_info_from_desc(desc, parsed_data)
                                addon_status = parsed_data.get('addon_status', '')
                                print(f"å¬å”¤å…½è£…å¤‡å¥—è£…è§£æç»“æœ: {addon_status}")
                                self.logger.debug(f"å¬å”¤å…½è£…å¤‡å¥—è£…è§£æç»“æœ: {addon_status}")
                        except Exception as e:
                            self.logger.warning(f"è§£æå¬å”¤å…½è£…å¤‡å¥—è£…ä¿¡æ¯å¤±è´¥: {e}")
                            # ä¿æŒåŸå§‹å€¼

                    if kindid in WEAPON_KINDIDS + ARMOR_KINDIDS:
                        addon_moli = self.equip_feature_extractor._extract_moli_from_agg_added_attrs(equip.get('agg_added_attrs', '[]'))

                    # ç›´æ¥ä¿å­˜æ‰€æœ‰åŸå§‹å­—æ®µï¼Œä¸åšè§£æ
                    equipment = {
                        # åŸºæœ¬å­—æ®µç›´æ¥æ˜ å°„
                        'eid': equip.get('eid'),
                        'equipid': equip.get('equipid'),
                        'equip_sn': equip.get('equip_sn'),
                        'server_name': equip.get('server_name'),
                        'serverid': equip.get('serverid'),
                        'equip_server_sn': equip.get('equip_server_sn'),
                        'seller_nickname': equip.get('seller_nickname'),
                        'seller_roleid': equip.get('seller_roleid'),
                        'area_name': equip.get('area_name'),
                        'equip_name': equip.get('equip_name'),
                        'equip_type': equip.get('equip_type'),
                        'equip_type_name': equip.get('equip_type_name'),
                        'equip_type_desc': equip.get('equip_type_desc'),
                        'level': equip.get('level'),
                        'equip_level': equip.get('equip_level'),
                        'equip_level_desc': equip.get('equip_level_desc'),
                        'level_desc': equip.get('level_desc'),
                        'subtitle': equip.get('subtitle'),
                        'equip_pos': equip.get('equip_pos'),
                        'position': equip.get('position'),
                        'school': equip.get('school'),
                        'role_grade_limit': equip.get('role_grade_limit'),
                        'min_buyer_level': equip.get('min_buyer_level'),
                        'equip_count': equip.get('equip_count'),
                        'price': equip.get('price'),
                        'price_desc': equip.get('price_desc'),
                        'unit_price_desc': equip.get('unit_price_desc'),
                        'min_unit_price': equip.get('min_unit_price'),
                        'accept_bargain': 1 if equip.get('accept_bargain') else 0,
                        'equip_status': equip.get('equip_status'),
                        'equip_status_desc': equip.get('equip_status_desc'),
                        'status_desc': equip.get('status_desc'),
                        'onsale_expire_time_desc': equip.get('onsale_expire_time_desc'),
                        'time_left': equip.get('time_left'),
                        'expire_time': equip.get('expire_time'),
                        'create_time_equip': equip.get('create_time'),
                        'selling_time': equip.get('selling_time'),
                        'selling_time_ago_desc': equip.get('selling_time_ago_desc'),
                        'first_onsale_time': equip.get('first_onsale_time'),
                        'pass_fair_show': equip.get('pass_fair_show'),
                        'fair_show_time': equip.get('fair_show_time'),
                        'fair_show_end_time': equip.get('fair_show_end_time'),
                        'fair_show_end_time_left': equip.get('fair_show_end_time_left'),
                        'fair_show_poundage': equip.get('fair_show_poundage'),
                        
                        # è£…å¤‡å±æ€§
                        'hp': equip.get('hp'),
                        'qixue': equip.get('qixue'),
                        'init_hp': equip.get('init_hp'),
                        'mofa': equip.get('mofa'),
                        'init_wakan': equip.get('init_wakan'),
                        'mingzhong': equip.get('mingzhong'),
                        'fangyu': equip.get('fangyu'),
                        'init_defense': equip.get('init_defense'),
                        'defense': equip.get('defense'),
                        'speed': equip.get('speed'),
                        'minjie': equip.get('minjie'),
                        'init_dex': equip.get('init_dex'),
                        'shanghai': equip.get('shanghai'),
                        'damage': equip.get('damage'),
                        'init_damage': equip.get('init_damage'),
                        'init_damage_raw': equip.get('init_damage_raw'),
                        'all_damage': equip.get('all_damage'),
                        'magic_damage': equip.get('magic_damage'),
                        'magic_defense': equip.get('magic_defense'),
                        'lingli': equip.get('lingli'),
                        'fengyin': equip.get('fengyin'),
                        'anti_fengyin': equip.get('anti_fengyin'),
                        'zongshang': equip.get('zongshang'),
                        
                        # ä¿®ç‚¼ç›¸å…³
                        'expt_gongji': equip.get('expt_gongji'),
                        'expt_fangyu': equip.get('expt_fangyu'),
                        'expt_fashu': equip.get('expt_fashu'),
                        'expt_kangfa': equip.get('expt_kangfa'),
                        'max_expt_gongji': equip.get('max_expt_gongji'),
                        'max_expt_fangyu': equip.get('max_expt_fangyu'),
                        'max_expt_fashu': equip.get('max_expt_fashu'),
                        'max_expt_kangfa': equip.get('max_expt_kangfa'),
                        'sum_exp': equip.get('sum_exp'),
                        
                        # å®å®ä¿®ç‚¼
                        'bb_expt_gongji': equip.get('bb_expt_gongji'),
                        'bb_expt_fangyu': equip.get('bb_expt_fangyu'),
                        'bb_expt_fashu': equip.get('bb_expt_fashu'),
                        'bb_expt_kangfa': equip.get('bb_expt_kangfa'),
                        
                        # é™„åŠ å±æ€§
                        'addon_tizhi': equip.get('addon_tizhi'),
                        'addon_liliang': equip.get('addon_liliang'),
                        'addon_naili': equip.get('addon_naili'),
                        'addon_minjie': equip.get('addon_minjie'),
                        'addon_fali': equip.get('addon_fali'),
                        'addon_lingli': equip.get('addon_lingli'),
                        'addon_moli': addon_moli,
                        'addon_total': equip.get('addon_total'),
                        'addon_status': addon_status,
                        'addon_skill_chance': equip.get('addon_skill_chance'),
                        'addon_effect_chance': equip.get('addon_effect_chance'),
                        
                        # å®çŸ³ç›¸å…³
                        'gem_level': equip.get('gem_level'),
                        'xiang_qian_level': equip.get('xiang_qian_level'),
                        
                        # å¼ºåŒ–ç›¸å…³
                        'jinglian_level': equip.get('jinglian_level'),
                        
                        # ç‰¹æŠ€å’Œå¥—è£…
                        'special_skill': equip.get('special_skill'),
                        'special_effect': json.dumps(equip.get('special_effect'), ensure_ascii=False) if equip.get('special_effect') else '',
                        'suit_skill': equip.get('suit_skill'),
                        'suit_effect': equip.get('suit_effect'),
                        
                        # å…¶ä»–ä¿¡æ¯
                        'collect_num': equip.get('collect_num'),
                        'has_collect': 1 if equip.get('has_collect') else 0,
                        'score': equip.get('score'),
                        'icon_index': equip.get('icon_index'),
                        'icon': equip.get('icon'),
                        'equip_face_img': equip.get('equip_face_img'),
                        'kindid': equip.get('kindid'),
                        'game_channel': equip.get('game_channel'),
                        
                        # è®¢å•ç›¸å…³
                        'game_ordersn': equip.get('game_ordersn'),
                        'whole_game_ordersn': equip.get('whole_game_ordersn'),
                        
                        # è·¨æœç›¸å…³
                        'allow_cross_buy': equip.get('allow_cross_buy'),
                        'cross_server_poundage': equip.get('cross_server_poundage'),
                        'cross_server_poundage_origin': equip.get('cross_server_poundage_origin'),
                        'cross_server_poundage_discount': equip.get('cross_server_poundage_discount'),
                        'cross_server_poundage_discount_label': equip.get('cross_server_poundage_discount_label'),
                        'cross_server_poundage_display_mode': equip.get('cross_server_poundage_display_mode'),
                        'cross_server_activity_conf_discount': equip.get('cross_server_activity_conf_discount'),
                        
                        # æ´»åŠ¨ç›¸å…³
                        'activity_type': equip.get('activity_type'),
                        'joined_seller_activity': 1 if equip.get('joined_seller_activity') else 0,
                        
                        # æ‹†åˆ†ç›¸å…³
                        'is_split_sale': 1 if equip.get('is_split_sale') else 0,
                        'is_split_main_role': 1 if equip.get('is_split_main_role') else 0,
                        'is_split_independent_role': 1 if equip.get('is_split_independent_role') else 0,
                        'is_split_independent_equip': 1 if equip.get('is_split_independent_equip') else 0,
                        'split_equip_sold_happen': 1 if equip.get('split_equip_sold_happen') else 0,
                        'show_split_equip_sold_remind': 1 if equip.get('show_split_equip_sold_remind') else 0,
                        
                        # ä¿æŠ¤ç›¸å…³
                        'is_onsale_protection_period': 1 if equip.get('is_onsale_protection_period') else 0,
                        'onsale_protection_end_time': equip.get('onsale_protection_end_time'),
                        'is_vip_protection': 1 if equip.get('is_vip_protection') else 0,
                        'is_time_lock': 1 if equip.get('is_time_lock') else 0,
                        
                        # æµ‹è¯•æœç›¸å…³
                        'equip_in_test_server': 1 if equip.get('equip_in_test_server') else 0,
                        'buyer_in_test_server': 1 if equip.get('buyer_in_test_server') else 0,
                        'equip_in_allow_take_away_server': 1 if equip.get('equip_in_allow_take_away_server') else 0,
                        
                        # å…¶ä»–æ ‡è¯†
                        'is_weijianding': 1 if equip.get('is_weijianding') else 0,
                        'is_show_alipay_privilege': 1 if equip.get('is_show_alipay_privilege') else 0,
                        'is_seller_redpacket_flag': 1 if equip.get('is_seller_redpacket_flag') else 0,
                        'is_show_expert_desc': equip.get('is_show_expert_desc'),
                        'is_show_special_highlight': 1 if equip.get('is_show_special_highlight') else 0,
                        'is_xyq_game_role_kunpeng_reach_limit': 1 if equip.get('is_xyq_game_role_kunpeng_reach_limit') else 0,
                        
                        # ç‰ˆæœ¬å’Œå­˜å‚¨ç›¸å…³
                        'equip_onsale_version': equip.get('equip_onsale_version'),
                        'storage_type': equip.get('storage_type'),
                        'agent_trans_time': equip.get('agent_trans_time'),
                        
                        # KOLç›¸å…³
                        'kol_article_id': equip.get('kol_article_id'),
                        'kol_share_id': equip.get('kol_share_id'),
                        'kol_share_time': equip.get('kol_share_time'),
                        'kol_share_status': equip.get('kol_share_status'),
                        
                        # æ¨èç›¸å…³
                        'reco_request_id': equip.get('reco_request_id'),
                        'appointed_roleid': equip.get('appointed_roleid'),
                        
                        # å›¢é˜Ÿç›¸å…³
                        'play_team_cnt': equip.get('play_team_cnt'),
                        
                        # éšæœºæŠ½å¥–ç›¸å…³
                        'random_draw_finish_time': equip.get('random_draw_finish_time'),
                        
                        # è¯¦ç»†æè¿°
                        'desc': equip.get('desc'),
                        'large_equip_desc': equip.get('large_equip_desc'),
                        'desc_sumup': equip.get('desc_sumup'),
                        'desc_sumup_short': equip.get('desc_sumup_short'),
                        'diy_desc': equip.get('diy_desc'),
                        'rec_desc': equip.get('rec_desc'),
                        
                        # æœç´¢ç›¸å…³
                        'search_type': equip.get('search_type'),
                        'tag': equip.get('tag'),
                        
                        # JSONæ ¼å¼å­—æ®µ
                        'gem_value': json.dumps(equip.get('gem_value'), ensure_ascii=False) if equip.get('gem_value') else '',
                        'price_explanation': json.dumps(equip.get('price_explanation'), ensure_ascii=False) if equip.get('price_explanation') else '',
                        'bargain_info': json.dumps(equip.get('bargain_info'), ensure_ascii=False) if equip.get('bargain_info') else '',
                        'diy_desc_pay_info': json.dumps(equip.get('diy_desc_pay_info'), ensure_ascii=False) if equip.get('diy_desc_pay_info') else '',
                        'other_info': equip.get('other_info', ''),
                        'video_info': json.dumps(equip.get('video_info'), ensure_ascii=False) if equip.get('video_info') else '',
                        'agg_added_attrs': json.dumps(extracted_attrs, ensure_ascii=False) if extracted_attrs else '',
                        'dynamic_tags': json.dumps(equip.get('dynamic_tags'), ensure_ascii=False) if equip.get('dynamic_tags') else '',
                        'highlight': json.dumps(equip.get('highlight'), ensure_ascii=False) if equip.get('highlight') else '',
                        'tag_key': equip.get('tag_key', ''),
                        
                        # åŸå§‹æ•°æ®
                        'raw_data_json': json.dumps(equip, ensure_ascii=False)
                    }
                    
                    equipments.append(equipment)
                    
                except Exception as e:
                    self.logger.error(f"è§£æå•ä¸ªè£…å¤‡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            return equipments
            
        except Exception as e:
            self.logger.error(f"è§£æJSONPå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None

    def get_search_params(self, use_browser=False, equip_type='normal'):
        """
        è·å–è£…å¤‡æœç´¢å‚æ•°
        - use_browser=True: å¯åŠ¨æµè§ˆå™¨æ‰‹åŠ¨è®¾ç½®å‚æ•°
        - use_browser=False: ä»æœ¬åœ°æ–‡ä»¶æˆ–é»˜è®¤é…ç½®åŠ è½½å‚æ•°
        - equip_type: 'normal', 'lingshi', 'pet'
        """
        params_file = f'config/equip_params_{equip_type}.json'
        
        # å¼ºåˆ¶æµè§ˆå™¨æ¨¡å¼ï¼šå¦‚æœuse_browserä¸ºTrueï¼Œåˆ™åˆ é™¤æ—§å‚æ•°æ–‡ä»¶
        if use_browser and os.path.exists(params_file):
            self.logger.info(f"å¼ºåˆ¶æµè§ˆå™¨æ¨¡å¼ï¼Œåˆ é™¤æ—§çš„å‚æ•°æ–‡ä»¶: {params_file}")
            os.remove(params_file)

        # æ ¹æ®åŒæ­¥/å¼‚æ­¥æ¨¡å¼é€‰æ‹©ä¸åŒçš„å‚æ•°è·å–å‡½æ•°
        # ï¼ˆå½“å‰çˆ¬è™«æ˜¯åŒæ­¥çš„ï¼Œæ‰€ä»¥ä½¿ç”¨åŒæ­¥å‡½æ•°ï¼‰
        params_getter_map = {
            'normal': get_equip_search_params_sync,
            'lingshi': get_lingshi_search_params_sync,
            'pet': get_pet_equip_search_params_sync
        }

        if equip_type not in params_getter_map:
            raise ValueError(f"ä¸æ”¯æŒçš„è£…å¤‡ç±»å‹: {equip_type}")

        return params_getter_map[equip_type](use_browser=use_browser)

    def fetch_page_sync(self, page=1, search_params=None, search_type='overall_search_equip'):
        """
        åŒæ­¥è·å–å•é¡µè£…å¤‡æ•°æ®
        """
        if search_params is None:
            search_params = {}
        
        # åŸºç¡€å‚æ•°
        params = {
            'act': search_type,
            'page': page
        }
        
        # åˆå¹¶æœç´¢å‚æ•°
        params.update(search_params)
        
        # æ„å»ºURL
        url = 'https://xyq.cbg.163.com/cgi-bin/xyq_overall_search.py?' + urlencode(params)
        self.logger.info(f"æ­£åœ¨è¯·æ±‚URL: {url}")
        
        try:
            response = self.session.get(url, timeout=20)
            response.raise_for_status()
            
            # è§£æJSONPå“åº”
            equipments = self.parse_jsonp_response(response.text)
            return equipments

        except Exception as e:
            self.logger.error(f"è·å–è£…å¤‡æ•°æ®å¤±è´¥ (é¡µç : {page}): {e}")
            return None

    def save_equipment_data(self, equipments):
        """ä¿å­˜è£…å¤‡æ•°æ®åˆ°MySQLæ•°æ®åº“"""
        if not equipments:
            self.logger.info("æ²¡æœ‰è£…å¤‡æ•°æ®éœ€è¦ä¿å­˜")
            return 0
        
        try:
            # ç¡®ä¿åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œæ•°æ®åº“æ“ä½œ
            from flask import current_app
            from src.app import create_app
            
            # å¦‚æœå½“å‰æ²¡æœ‰åº”ç”¨ä¸Šä¸‹æ–‡ï¼Œåˆ›å»ºä¸€ä¸ª
            if not current_app:
                app = create_app()
                with app.app_context():
                    return self._save_equipment_data_with_context(equipments)
            else:
                return self._save_equipment_data_with_context(equipments)
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜è£…å¤‡æ•°æ®åˆ°MySQLæ•°æ®åº“å¤±è´¥: {e}")
            return 0
    
    def _filter_equipment_fields(self, equipments):
        """
        è¿‡æ»¤è£…å¤‡å­—æ®µï¼Œåªä¿ç•™ç¼“å­˜æ‰€éœ€å­—æ®µï¼ˆä¼˜åŒ–å†…å­˜å ç”¨ï¼‰
        
        Args:
            equipments: è£…å¤‡æ•°æ®åˆ—è¡¨
            
        Returns:
            list: è¿‡æ»¤åçš„è£…å¤‡æ•°æ®åˆ—è¡¨
        """
        from src.evaluator.constants.equipment_types import EQUIPMENT_CACHE_REQUIRED_FIELDS
        
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ï¼Œæ›´é«˜æ•ˆ
        return [
            {k: v for k, v in equipment.items() if k in EQUIPMENT_CACHE_REQUIRED_FIELDS}
            for equipment in equipments
        ]
    
    def _get_redis_total_count(self):
        """
        è·å–Redisä¸­çš„è£…å¤‡æ€»æ¡æ•°
        
        Returns:
            int: Redisä¸­çš„è£…å¤‡æ€»æ¡æ•°ï¼Œè·å–å¤±è´¥è¿”å›0
        """
        try:
            from src.evaluator.market_anchor.equip.equip_market_data_collector import EquipMarketDataCollector
            from src.utils.redis_cache import get_redis_cache
            
            collector = EquipMarketDataCollector.get_instance()
            redis_cache = get_redis_cache()
            
            if redis_cache and redis_cache.is_available():
                # è·å–Redis Hashçš„æ€»æ¡æ•°
                full_key = redis_cache._make_key(collector._full_cache_key)
                total_count = redis_cache.client.hlen(full_key)
                self.logger.debug(f"Redisè£…å¤‡æ€»æ¡æ•°: {total_count}")
                return total_count
            else:
                self.logger.warning("Redisä¸å¯ç”¨ï¼Œæ— æ³•è·å–æ€»æ¡æ•°")
                return 0
                
        except Exception as e:
            self.logger.warning(f"è·å–Redisæ€»æ¡æ•°å¤±è´¥: {e}")
            return 0
    
    def _publish_dataframe_message(self, new_data_df, data_count):
        """
        å‘å¸ƒDataFrameæ¶ˆæ¯åˆ°Redisï¼ˆç«‹å³é€šçŸ¥å‰ç«¯ï¼Œåªæ›´æ–°å†…å­˜æ•°æ®ï¼Œä¸åŒ…å«æ€»æ•°ï¼‰
        
        Args:
            new_data_df: DataFrameæ•°æ®
            data_count: æœ¬æ¬¡æ–°å¢çš„æ•°æ®æ¡æ•°
            
        Returns:
            bool: å‘å¸ƒæ˜¯å¦æˆåŠŸ
        """
        try:
            from src.utils.redis_pubsub import get_redis_pubsub, MessageType, Channel
            
            pubsub = get_redis_pubsub()
            message = {
                'type': MessageType.EQUIPMENT_DATA_SAVED,
                'data_count': data_count,  # æœ¬æ¬¡æ•°æ®é‡
                'action': 'add_dataframe'  # åªç”¨äºç«‹å³æ›´æ–°å†…å­˜ç¼“å­˜
            }
            
            success = pubsub.publish_with_dataframe(Channel.EQUIPMENT_UPDATES, message, new_data_df)
            if success:
                self.logger.info(f"ğŸ“¢ å·²ç«‹å³å‘å¸ƒDataFrameæ¶ˆæ¯åˆ°Redis (æœ¬æ¬¡:{data_count}æ¡)")
            else:
                self.logger.warning("âš ï¸ å‘å¸ƒDataFrameæ¶ˆæ¯å¤±è´¥")
            
            return success
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ å‘å¸ƒDataFrameæ¶ˆæ¯å¤±è´¥: {e}")
            return False
    
    def _batch_save_to_mysql(self, equipments):
        """
        æ‰¹é‡ä¿å­˜åˆ°MySQLï¼Œä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
        
        Args:
            equipments: è£…å¤‡æ•°æ®åˆ—è¡¨
            
        Returns:
            tuple: (æ–°å¢æ•°é‡, æ›´æ–°æ•°é‡)
        """
        try:
            # æ‰¹é‡æŸ¥è¯¢å·²å­˜åœ¨çš„è£…å¤‡ï¼ˆä¸€æ¬¡æŸ¥è¯¢ä»£æ›¿Næ¬¡æŸ¥è¯¢ï¼‰
            equip_sns = [eq.get('equip_sn') for eq in equipments if eq.get('equip_sn')]
            
            existing_equipments = {}
            if equip_sns:
                existing_list = db.session.query(Equipment).filter(
                    Equipment.equip_sn.in_(equip_sns)
                ).all()
                existing_equipments = {eq.equip_sn: eq for eq in existing_list}
            
            new_equipments = []
            updated_count = 0
            
            # éå†è£…å¤‡æ•°æ®ï¼Œåˆ†ç±»ä¸ºæ–°å¢å’Œæ›´æ–°
            for equipment_data in equipments:
                try:
                    equip_sn = equipment_data.get('equip_sn')
                    
                    if equip_sn and equip_sn in existing_equipments:
                        # æ›´æ–°ç°æœ‰è®°å½•
                        existing = existing_equipments[equip_sn]
                        for key, value in equipment_data.items():
                            if hasattr(existing, key):
                                setattr(existing, key, value)
                        existing.update_time = datetime.now()
                        updated_count += 1
                    else:
                        # å‡†å¤‡æ–°è®°å½•
                        new_equipments.append(Equipment(**equipment_data))
                        
                except Exception as e:
                    self.logger.error(f"å¤„ç†å•ä¸ªè£…å¤‡æ•°æ®å¤±è´¥: {e}")
                    continue
            
            # æ‰¹é‡æ’å…¥æ–°è®°å½•
            if new_equipments:
                db.session.bulk_save_objects(new_equipments)
            
            # æäº¤äº‹åŠ¡
            db.session.commit()
            
            if len(new_equipments) > 0:
                self.logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(new_equipments)} æ¡æ–°è£…å¤‡æ•°æ®åˆ°MySQLæ•°æ®åº“")
            if updated_count > 0:
                self.logger.info(f"âœ… æ›´æ–° {updated_count} æ¡å·²å­˜åœ¨çš„è£…å¤‡æ•°æ®")
            
            return len(new_equipments), updated_count
            
        except Exception as e:
            db.session.rollback()
            self.logger.error(f"æ‰¹é‡ä¿å­˜MySQLå¤±è´¥: {e}")
            raise
    
    def _sync_to_redis_cache(self, new_data_df):
        """
        åŒæ­¥æ–°æ•°æ®åˆ°Redisç¼“å­˜
        
        Args:
            new_data_df: æ–°æ•°æ®çš„DataFrame
            
        Returns:
            bool: åŒæ­¥æ˜¯å¦æˆåŠŸ
        """
        try:
            from src.evaluator.market_anchor.equip.equip_market_data_collector import EquipMarketDataCollector
            
            collector = EquipMarketDataCollector.get_instance()
            redis_success = collector._sync_new_data_to_redis(new_data_df)
            
            if redis_success:
                self.logger.info("âœ… æ–°æ•°æ®å·²åŒæ­¥åˆ°Redisç¼“å­˜")
            else:
                self.logger.warning("âš ï¸ æ–°æ•°æ®åŒæ­¥åˆ°Rediså¤±è´¥")
            
            return redis_success
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ åŒæ­¥æ–°æ•°æ®åˆ°Rediså¤±è´¥: {e}")
            return False
    
    def _save_equipment_data_with_context(self, equipments):
        """åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­ä¿å­˜è£…å¤‡æ•°æ® - å†…å­˜ç¼“å­˜ä¼˜å…ˆå¿«é€Ÿå“åº” â†’ MySQL â†’ Redis"""
        try:
            # åœ¨å­çº¿ç¨‹ä¸­é‡æ–°å¯¼å…¥pandasï¼Œç¡®ä¿å¯ç”¨
            import pandas as pd
            
            if not equipments:
                self.logger.info("æ²¡æœ‰è£…å¤‡æ•°æ®éœ€è¦ä¿å­˜")
                return 0
            
            self.logger.info(f"å¼€å§‹ä¿å­˜ {len(equipments)} æ¡è£…å¤‡æ•°æ®...")
            
            # ä¼˜åŒ–ï¼šåªè¿‡æ»¤ä¸€æ¬¡ï¼Œé¿å…é‡å¤ä»£ç 
            filtered_equipments = self._filter_equipment_fields(equipments)
            new_data_df = pd.DataFrame(filtered_equipments)
            
            # ç¬¬ä¸€æ­¥ï¼šç«‹å³å‘å¸ƒDataFrameæ¶ˆæ¯ï¼Œå¿«é€Ÿæ›´æ–°å†…å­˜ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œè¶…å¿«å“åº”ï¼‰
            publish_success = self._publish_dataframe_message(new_data_df, len(equipments))
            
            if publish_success:
                self.logger.info(f"âœ… å·²ç«‹å³é€šçŸ¥å†…å­˜ç¼“å­˜æ›´æ–° {len(equipments)} æ¡æ•°æ®ï¼ˆå¿«é€Ÿå“åº”ï¼‰")
            else:
                self.logger.warning(f"âš ï¸ å†…å­˜ç¼“å­˜é€šçŸ¥å‘é€å¤±è´¥ï¼Œä½†ç»§ç»­ä¿å­˜åˆ°æ•°æ®åº“")
            
            # ç¬¬äºŒæ­¥ï¼šå¼‚æ­¥æ‰¹é‡ä¿å­˜åˆ°MySQLå’ŒRedisï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            self._submit_async_save_task(equipments, new_data_df)
            
            self.logger.info(f"ğŸ‰ è£…å¤‡æ•°æ®ä¿å­˜æµç¨‹: å†…å­˜ç¼“å­˜(âœ…å·²é€šçŸ¥) â†’ MySQL(å¤„ç†ä¸­) â†’ Redis(å¤„ç†ä¸­)")
            
            # è¿”å›é¢„ä¼°çš„æ–°å¢æ•°é‡ï¼ˆå®é™…æ•°é‡ç”±å¼‚æ­¥ä»»åŠ¡è®¡ç®—ï¼‰
            return len(equipments)
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜è£…å¤‡æ•°æ®å¤±è´¥: {e}")
            return 0
    
    def _submit_async_save_task(self, equipments, new_data_df):
        """
        æäº¤å¼‚æ­¥ä¿å­˜ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        
        Args:
            equipments: è£…å¤‡æ•°æ®åˆ—è¡¨
            new_data_df: è¿‡æ»¤åçš„DataFrame
        """
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œä¿å­˜ä»»åŠ¡
            future = self._executor.submit(
                self._async_batch_save_worker,
                equipments,
                new_data_df
            )
            
            # æ·»åŠ å®Œæˆå›è°ƒï¼Œè®°å½•ç»“æœ
            future.add_done_callback(self._async_save_callback)
            
        except Exception as e:
            self.logger.error(f"âŒ æäº¤å¼‚æ­¥ä¿å­˜ä»»åŠ¡å¤±è´¥: {e}")
    
    def _async_save_callback(self, future):
        """å¼‚æ­¥ä¿å­˜ä»»åŠ¡å®Œæˆå›è°ƒ - è®°å½•MySQLå’ŒRedisä¿å­˜ç»“æœ"""
        try:
            result = future.result()
            if result:
                saved_count, updated_count, saved_dataframe, redis_synced = result
                self.logger.info(
                    f"âœ… å¼‚æ­¥ä¿å­˜å®Œæˆ: æ–°å¢ {saved_count} æ¡, æ›´æ–° {updated_count} æ¡, RedisåŒæ­¥: {'æˆåŠŸ' if redis_synced else 'å¤±è´¥'}"
                )
                
                # å†…å­˜ç¼“å­˜å·²åœ¨ä¸»çº¿ç¨‹ä¸­ç«‹å³æ›´æ–°ï¼Œè¿™é‡Œä¸å†å‘é€æ¶ˆæ¯
                if saved_count > 0 and redis_synced:
                    self.logger.info(f"âœ… MySQLå’ŒRedisä¿å­˜æˆåŠŸï¼Œæ•°æ®ä¸€è‡´æ€§å·²ä¿è¯")
                elif saved_count > 0 and not redis_synced:
                    self.logger.warning(f"âš ï¸ MySQLä¿å­˜æˆåŠŸä½†RedisåŒæ­¥å¤±è´¥ï¼Œå†…å­˜å’ŒMySQLå·²æœ‰æ•°æ®ï¼Œéœ€æ‰‹åŠ¨åŒæ­¥Redis")
                elif updated_count > 0:
                    self.logger.info(f"ğŸ“ æ— æ–°å¢æ•°æ®ï¼Œæ›´æ–°äº† {updated_count} æ¡ç°æœ‰æ•°æ®")
                
        except Exception as e:
            self.logger.error(f"âŒ å¼‚æ­¥ä¿å­˜ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
    
    def _publish_save_complete_message(self, saved_count, updated_count):
        """
        å‘å¸ƒä¿å­˜å®Œæˆæ¶ˆæ¯ï¼ˆå¯é€‰ï¼Œç”¨äºæ˜¾ç¤ºå®é™…æ–°å¢å’Œæ›´æ–°æ•°é‡ï¼‰
        
        Args:
            saved_count: æ–°å¢æ•°é‡
            updated_count: æ›´æ–°æ•°é‡
        """
        try:
            from src.utils.redis_pubsub import get_redis_pubsub, MessageType, Channel
            
            pubsub = get_redis_pubsub()
            message = {
                'type': MessageType.EQUIPMENT_DATA_SAVED,
                'data_count': saved_count,  # æœ¬æ¬¡å®é™…æ–°å¢æ•°é‡
                'updated_count': updated_count,  # æœ¬æ¬¡æ›´æ–°æ•°é‡
                'action': 'save_complete'  # æ ‡è¯†è¿™æ˜¯ä¿å­˜å®Œæˆæ¶ˆæ¯
            }
            
            # ä¸éœ€è¦DataFrameï¼Œåªå‘é€æ¶ˆæ¯
            success = pubsub.publish(Channel.EQUIPMENT_UPDATES, message)
            if success:
                self.logger.info(f"ğŸ“¢ å·²å‘å¸ƒä¿å­˜å®Œæˆæ¶ˆæ¯ (æ–°å¢:{saved_count}, æ›´æ–°:{updated_count})")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ å‘å¸ƒä¿å­˜å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")
    
    def _async_batch_save_worker(self, equipments, new_data_df):
        """
        å¼‚æ­¥æ‰¹é‡ä¿å­˜å·¥ä½œçº¿ç¨‹ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰- MySQL â†’ Redis â†’ é€šçŸ¥å†…å­˜ç¼“å­˜
        
        Args:
            equipments: è£…å¤‡æ•°æ®åˆ—è¡¨
            new_data_df: è¿‡æ»¤åçš„DataFrame
            
        Returns:
            tuple: (æ–°å¢æ•°é‡, æ›´æ–°æ•°é‡, å®é™…ä¿å­˜çš„DataFrame, RedisåŒæ­¥çŠ¶æ€)
        """
        try:
            # åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œæ•°æ®åº“æ“ä½œ
            from src.app import create_app
            app = create_app()
            
            with app.app_context():
                self.logger.info(f"ğŸ”„ å¼‚æ­¥ä»»åŠ¡å¼€å§‹å¤„ç† {len(equipments)} æ¡è£…å¤‡æ•°æ®...")
                
                # ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡ä¿å­˜åˆ°MySQL
                saved_count, updated_count = self._batch_save_to_mysql(equipments)
                
                # ç¬¬äºŒæ­¥ï¼šåŒæ­¥åˆ°Redisï¼ˆåªåœ¨æœ‰æ–°æ•°æ®æ—¶ï¼‰
                redis_synced = False
                saved_dataframe = None
                
                if saved_count > 0:
                    # åŒæ­¥åˆ°Redisç¼“å­˜
                    redis_synced = self._sync_to_redis_cache(new_data_df)
                    
                    if redis_synced:
                        # è¿”å›å®é™…æ–°å¢çš„æ•°æ®ï¼ˆç”¨äºé€šçŸ¥å†…å­˜ç¼“å­˜æ›´æ–°ï¼‰
                        saved_dataframe = new_data_df.copy()
                        self.logger.info(f"âœ… MySQLå’ŒRedisä¿å­˜æˆåŠŸï¼Œå‡†å¤‡é€šçŸ¥å†…å­˜ç¼“å­˜æ›´æ–°")
                    else:
                        self.logger.warning(f"âš ï¸ MySQLä¿å­˜æˆåŠŸä½†RedisåŒæ­¥å¤±è´¥ï¼Œä¸æ›´æ–°å†…å­˜ç¼“å­˜")
                
                return saved_count, updated_count, saved_dataframe, redis_synced
                
        except Exception as e:
            self.logger.error(f"âŒ å¼‚æ­¥æ‰¹é‡ä¿å­˜å·¥ä½œçº¿ç¨‹å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return 0, 0, None, False
    
    def __del__(self):
        """ææ„æ–¹æ³•ï¼Œç¡®ä¿çº¿ç¨‹æ± æ­£ç¡®å…³é—­"""
        try:
            if hasattr(self, '_executor'):
                self.logger.info("æ­£åœ¨å…³é—­çº¿ç¨‹æ± ...")
                self._executor.shutdown(wait=True, cancel_futures=False)
                self.logger.info("çº¿ç¨‹æ± å·²å…³é—­")
        except Exception as e:
            # ææ„æ—¶å¯èƒ½loggerå·²ç»è¢«å›æ”¶
            print(f"å…³é—­çº¿ç¨‹æ± æ—¶å‡ºé”™: {e}")

    async def fetch_page(self, page=1, search_params=None, search_type='overall_search_equip'):
        """
        è·å–å•é¡µè£…å¤‡æ•°æ®
        
        Args:
            page: é¡µç 
            search_params: æœç´¢å‚æ•°
            search_type: æœç´¢ç±»å‹
            
        Returns:
            list: è§£æåçš„è£…å¤‡æ•°æ®
        """
        try:
            # ç¡®ä¿search_paramsä¸ä¸ºNone
            if search_params is None:
                # æ ¹æ®search_typeæä¾›ä¸€ä¸ªåŸºç¡€çš„é»˜è®¤å€¼
                if search_type == 'overall_search_lingshi':
                    search_params = { 'level_min': 60, 'level_max': 140 }
                elif search_type == 'overall_search_pet_equip':
                    search_params = { 'level_min': 5, 'level_max': 145 }
                else:
                    search_params = { 'level_min': 60, 'level_max': 160 }

            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                **search_params,  # æ·»åŠ æœç´¢å‚æ•°
                'callback': 'Request.JSONP.request_map.request_0',
                '_': str(int(time.time() * 1000)),
                'act': 'recommd_by_role',
                'page': page,
                'count': 15,
                'search_type': search_type,
                'server_type': 3,# é»˜è®¤3å¹´å¤–æœåŠ¡å™¨
            }
            
            # æ„å»ºå®Œæ•´URL
            url = f"{self.base_url}?{urlencode(params)}"
            
            # ä½¿ç”¨Playwrightå‘é€è¯·æ±‚
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context()
                
                # è®¾ç½®cookies
                cookies = get_playwright_cookies_for_context(self.logger)
                if cookies:
                    await context.add_cookies(cookies)
                
                page_obj = await context.new_page()
                response = await page_obj.goto(url)
                
                if response:
                    text = await response.text()
                    await browser.close()
                    
                    # è§£æå“åº”
                    parsed_result = self.parse_jsonp_response(text)
                    return parsed_result
                
                await browser.close()
                return None
                
        except Exception as e:
            self.logger.error(f"è·å–è£…å¤‡ç¬¬{page}é¡µæ•°æ®æ—¶å‡ºé”™: {e}")
            return None

    async def crawl_all_pages_async(self, max_pages=10, delay_range=None, use_browser=False, equip_type='normal', cached_params=None):
        """
        å¼‚æ­¥çˆ¬å–æ‰€æœ‰è£…å¤‡é¡µé¢
        - equip_type: 'normal', 'lingshi', 'pet'
        """
        # é¦–å…ˆéªŒè¯Cookieæœ‰æ•ˆæ€§
        self.logger.info("æ­£åœ¨éªŒè¯Cookieæœ‰æ•ˆæ€§...")
        print("å³å°†è°ƒç”¨ verify_cookie_validity_async")
        from src.utils.cookie_manager import verify_cookie_validity_async
        is_valid = await verify_cookie_validity_async(self.logger)
        print("verify_cookie_validity_async è¿”å›ï¼š", is_valid)
        if not is_valid:
            self.logger.warning("CookieéªŒè¯å¤±è´¥ï¼Œæ­£åœ¨æ›´æ–°Cookie...")
            from src.utils.cookie_manager import _update_cookies_internal
            if not await _update_cookies_internal():
                self.logger.error("Cookieæ›´æ–°å¤±è´¥ï¼Œæ— æ³•ç»§ç»­çˆ¬å–")
                return
            else:
                self.logger.info("Cookieæ›´æ–°æˆåŠŸï¼Œé‡æ–°è®¾ç½®ä¼šè¯")
                # é‡æ–°è®¾ç½®ä¼šè¯
                self.setup_session()
        else:
            self.logger.info("CookieéªŒè¯é€šè¿‡")

        search_type_map = {
            'normal': 'overall_search_equip',
            'lingshi': 'overall_search_lingshi',
            'pet': 'overall_search_pet_equip',
        }
        search_type = search_type_map.get(equip_type)
        if not search_type:
            self.logger.error(f"æœªçŸ¥çš„è£…å¤‡ç±»å‹: {equip_type}")
            return

        self.logger.info(f" å¼€å§‹ {equip_type} è£…å¤‡çˆ¬å–ï¼Œæœ€å¤§é¡µæ•°: {max_pages}")

        # è·å–å‚æ•°
        params_getter_async_map = {
            'normal': get_equip_search_params_async,
            'lingshi': get_lingshi_search_params_async,
            'pet': get_pet_equip_search_params_async
        }
        params_file = f'config/equip_params_{equip_type}.json'
        
        # å¼ºåˆ¶æµè§ˆå™¨æ¨¡å¼ï¼šå¦‚æœuse_browserä¸ºTrueï¼Œåˆ™åˆ é™¤æ—§å‚æ•°æ–‡ä»¶
        if use_browser and os.path.exists(params_file):
            self.logger.info(f"å¼ºåˆ¶æµè§ˆå™¨æ¨¡å¼ï¼Œåˆ é™¤æ—§çš„å‚æ•°æ–‡ä»¶: {params_file}")
            os.remove(params_file)
        
        # ä½¿ç”¨ä¼ å…¥çš„ç¼“å­˜å‚æ•°æˆ–è·å–æ–°å‚æ•°
        if cached_params and not use_browser:
            if 'server_id' in cached_params:
                # å»æ‰search_typeä¸­çš„'overall_'
                if equip_type == 'normal':
                    search_type = 'search_role_equip'
                else:
                    search_type = search_type.replace('overall_', '')
            search_params = cached_params
            self.logger.info(f" ä½¿ç”¨ä¼ å…¥çš„ç¼“å­˜å‚æ•°: {len(search_params)} ä¸ª")
        else:
            search_params = await params_getter_async_map[equip_type](use_browser=use_browser)
            if search_params:
                self.logger.info(f" ä½¿ç”¨æœç´¢å‚æ•°: {len(search_params)} ä¸ª")

        if not search_params:
            self.logger.error(f"æ— æ³•è·å– {equip_type} è£…å¤‡çš„æœç´¢å‚æ•°ï¼Œçˆ¬å–ä¸­æ­¢")
            return
            
        total_saved_count = 0
        successful_pages = 0
        
        for page_num in range(1, max_pages + 1):
            try:
                # ç¡®ä¿æ—¥å¿—ç«‹å³è¾“å‡º
                self.logger.info(f"ğŸ“„ æ­£åœ¨çˆ¬å– {equip_type} è£…å¤‡ç¬¬ {page_num} é¡µ...")
                # å¼ºåˆ¶åˆ·æ–°æ—¥å¿—ç¼“å†²
                import sys
                sys.stdout.flush()
                
                equipments = await self.fetch_page(page_num, search_params, search_type)
                
                if equipments is None:
                    self.logger.warning(f" ç¬¬ {page_num} é¡µæ•°æ®è·å–å¤±è´¥ï¼Œå°è¯•é‡è¯•...")
                    await asyncio.sleep(5) # ç­‰å¾…5ç§’é‡è¯•
                    equipments = await self.fetch_page(page_num, search_params, search_type)

                if equipments:
                    saved_count = self.save_equipment_data(equipments)
                    total_saved_count += saved_count
                    successful_pages += 1
                    
                    # æ‰“å°æ¯æ¡è£…å¤‡çš„ç®€è¦ä¿¡æ¯
                    for equipment in equipments:
                        price = equipment.get('price_desc', equipment.get('price', 'æœªçŸ¥'))
                        equip_name = equipment.get('equip_name', 'æœªçŸ¥è£…å¤‡')
                        level = equipment.get('level', 'æœªçŸ¥')
                        server_name = equipment.get('server_name', 'æœªçŸ¥æœåŠ¡å™¨')
                        seller_nickname = equipment.get('seller_nickname', 'æœªçŸ¥å–å®¶')
                        self.logger.info(f"ï¿¥{price} - {equip_name}({level}çº§) - {server_name} - {seller_nickname}")
                    
                    self.logger.info(f" ç¬¬ {page_num} é¡µå®Œæˆï¼Œè·å– {len(equipments)} æ¡è£…å¤‡ï¼Œä¿å­˜ {saved_count} æ¡")
                    
                    # åˆ¤æ–­æ•°æ®æ¡æ•°æ˜¯å¦ä¸è¶³10æ¡ï¼Œå¦‚æœä¸è¶³åˆ™è¯´æ˜æ²¡æœ‰ä¸‹ä¸€é¡µ
                    if len(equipments) < 10:
                        self.logger.info(f"ğŸ“„ ç¬¬ {page_num} é¡µæ•°æ®æ¡æ•°({len(equipments)})ä¸è¶³10æ¡ï¼Œåˆ¤æ–­ä¸ºæœ€åä¸€é¡µï¼Œçˆ¬å–ç»“æŸ")
                        break
                else:
                    self.logger.info(f"ğŸ“„ ç¬¬ {page_num} é¡µæ²¡æœ‰æ•°æ®ï¼Œçˆ¬å–ç»“æŸ")
                    break 

                # æ·»åŠ å»¶è¿Ÿ
                if delay_range and page_num < max_pages:  # æœ€åä¸€é¡µä¸éœ€è¦å»¶è¿Ÿ
                    delay = random.uniform(delay_range[0], delay_range[1])
                    self.logger.info(f"â³ ç­‰å¾… {delay:.2f} ç§’åç»§ç»­...")
                    await asyncio.sleep(delay)
                    
            except Exception as e:
                self.logger.error(f"å¤„ç†ç¬¬ {page_num} é¡µæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                break

        self.logger.info(f" {equip_type} è£…å¤‡çˆ¬å–å®Œæˆï¼æˆåŠŸé¡µæ•°: {successful_pages}/{max_pages}, æ€»è£…å¤‡æ•°: {total_saved_count}")
        
        # å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ—¥å¿—ç¼“å†²åŒºï¼Œç¡®ä¿æ—¥å¿—è¢«å®Œæ•´å†™å…¥æ–‡ä»¶
        import sys
        sys.stdout.flush()
        sys.stderr.flush()
        
        # åˆ·æ–°æ—¥å¿—å¤„ç†å™¨ç¼“å†²åŒº
        for handler in self.logger.handlers:
            if hasattr(handler, 'flush'):
                handler.flush()

    def crawl_all_pages(self, max_pages=10, delay_range=None, use_browser=False, equip_type='normal', cached_params=None):
        """
        åŒæ­¥å¯åŠ¨å¼‚æ­¥è£…å¤‡çˆ¬è™«çš„å…¥å£
        """
        try:
            asyncio.run(self.crawl_all_pages_async(
                max_pages=max_pages,
                delay_range=delay_range,
                use_browser=use_browser,
                equip_type=equip_type,
                cached_params=cached_params
            ))
        except Exception as e:
            self.logger.error(f"å¯åŠ¨è£…å¤‡çˆ¬è™«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()