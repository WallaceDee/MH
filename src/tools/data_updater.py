#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è§£ææ¯ä¸ªè§’è‰²çš„ large_equip_desc æ•°æ®
æ•°æ®æ›´æ–°å·¥å…· - ç”¨äºæ›´æ–°å†å²æ•°æ®
"""

import os
import json
import sqlite3
import logging
from datetime import datetime
import sys
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
from src.utils.project_path import get_project_root
project_root = get_project_root()
sys.path.append(project_root)

from src.parser.pet_parser import PetParser
from src.parser.equipment_parser import EquipmentParser
from src.parser.shenqi_parser import ShenqiParser
from src.parser.rider_parser import RiderParser
from src.parser.ex_avt_parser import ExAvtParser
from src.utils.lpc_helper import LPCHelper
from src.parser.common_parser import CommonParser
from src.parser.fabao_parser import FabaoParser

# å¯¼å…¥ç‰¹å¾æå–å™¨
from src.evaluator.feature_extractor.lingshi_feature_extractor import LingshiFeatureExtractor

class DataUpdater:
    def __init__(self, db_path, logger=None):
        self.db_path = db_path
        self.logger = logger or logging.getLogger(__name__)
        
        # åˆå§‹åŒ–è§£æå™¨
        self.pet_parser = PetParser(self.logger)
        self.equipment_parser = EquipmentParser(self.logger)
        self.shenqi_parser = ShenqiParser(self.logger)
        self.rider_parser = RiderParser(self.logger)
        self.ex_avt_parser = ExAvtParser(self.logger)
        self.lpc_helper = LPCHelper(self.logger)
        self.common_parser = CommonParser(self.logger)
        self.fabao_parser = FabaoParser(self.logger)
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        self.lingshi_feature_extractor = LingshiFeatureExtractor()

    def update_role_data(self, role_id=None):
        """
        æ›´æ–°è§’è‰²æ•°æ®
        
        Args:
            role_id: è¦æ›´æ–°çš„è§’è‰²IDï¼Œå¦‚æœä¸ºNoneåˆ™æ›´æ–°æ‰€æœ‰è§’è‰²
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–è¦æ›´æ–°çš„è§’è‰²
            if role_id:
                cursor.execute("""
                    SELECT c.equip_id, c.seller_nickname, d.raw_data_json
                    FROM roles c
                    JOIN large_equip_desc_data d ON c.equip_id = d.equip_id
                    WHERE c.equip_id = ?
                """, (role_id,))
            else:
                cursor.execute("""
                    SELECT c.equip_id, c.seller_nickname, d.raw_data_json
                    FROM roles c
                    JOIN large_equip_desc_data d ON c.equip_id = d.equip_id
                """)
            
            roles = cursor.fetchall()
            updated_count = 0
            
            for char in roles:
                try:
                    # è·å–åŸå§‹æ•°æ®
                    equip_id = char[0]  # equip_id
                    seller_nickname = char[1]  # seller_nickname
                    raw_data_json = char[2]  # raw_data_json from large_equip_desc_data
                    
                    if not raw_data_json:
                        continue
                    
                    try:
                        # è§£æJSONå­—ç¬¦ä¸²ä¸ºPythonå¯¹è±¡
                        parsed_desc = json.loads(raw_data_json)
                    except json.JSONDecodeError as e:
                        self.logger.error(f"è§£æJSONæ•°æ®å¤±è´¥ (equip_id: {equip_id}): {e}")
                        continue
                    
                    if not parsed_desc:
                        continue
                    
                    # æ›´æ–°å„ä¸ªå­—æ®µ
                    updates = {}
                    
                    # # æ›´æ–°è‚²å…½æœ¯
                    # yushoushu_skill = self.common_parser.parse_yushoushu_skill(parsed_desc.get('all_skills', {}))
                    # self.logger.info(f"æ›´æ–°è§’è‰² {equip_id} çš„è‚²å…½æœ¯æ•°æ®æˆåŠŸ: {yushoushu_skill}")
                    # updates['yushoushu_skill'] = yushoushu_skill
                    
                    # æ›´æ–°æ³•å®æ•°æ®
                    fabao = self.fabao_parser.process_role_fabao(parsed_desc, seller_nickname)
                    if fabao:
                        updates['all_fabao_json'] = json.dumps(fabao, ensure_ascii=False)
                    
                    # # æ›´æ–°å¬å”¤å…½æ•°æ®
                    # pets = self.pet_parser.process_role_pets(parsed_desc, seller_nickname)
                    # if pets:
                    #     updates['all_pets_json'] = json.dumps(pets, ensure_ascii=False)
                    
                    # # æ›´æ–°è£…å¤‡æ•°æ®
                    # if parsed_desc and 'AllEquip' in parsed_desc:
                    #     equip_info = self.equipment_parser.process_role_equipment(
                    #         parsed_desc, seller_nickname
                    #     )
                    #     if equip_info:
                    #         updates['all_equip_json'] = json.dumps(equip_info, ensure_ascii=False)
                    
                    # # æ›´æ–°ç¥å™¨æ•°æ®
                    # if parsed_desc and parsed_desc.get('shenqi'):
                    #     all_shenqi = self.shenqi_parser.process_role_shenqi(parsed_desc, seller_nickname)
                    #     if all_shenqi and all_shenqi.get('ç¥å™¨åç§°'):
                    #         updates['all_shenqi_json'] = json.dumps(all_shenqi, ensure_ascii=False)
                    
                    # # æ›´æ–°åéª‘æ•°æ®
                    # if parsed_desc and parsed_desc.get('AllRider'):
                    #     all_rider = self.rider_parser.process_role_rider(
                    #         {'rider': parsed_desc.get('AllRider')}, seller_nickname
                    #     )
                    #     if all_rider and all_rider.get('åéª‘åˆ—è¡¨'):
                    #         updates['all_rider_json'] = json.dumps(all_rider, ensure_ascii=False)
                    
                    # æ›´æ–°é”¦è¡£æ•°æ®
                    if parsed_desc and parsed_desc.get('ExAvt'):
                        ex_avt_data = {
                            'ExAvt': parsed_desc.get('ExAvt'),
                            'basic_info': {
                                'total_avatar': parsed_desc.get('total_avatar', 0),
                                'xianyu': parsed_desc.get('xianyu', 0),
                                'xianyu_score': parsed_desc.get('xianyu_score', 0),
                                'qicai_score': parsed_desc.get('qicai_score', 0)
                            },
                            'chat_effect': parsed_desc.get('chat_effect'),
                            'icon_effect': parsed_desc.get('icon_effect'),
                            'title_effect': parsed_desc.get('title_effect'),
                            'perform_effect': parsed_desc.get('perform_effect'),
                            'achieve_show': parsed_desc.get('achieve_show', []),
                            'avt_widget': parsed_desc.get('avt_widget', {})
                        }
                        all_ex_avt = self.ex_avt_parser.process_role_clothes(ex_avt_data, seller_nickname)
                        if all_ex_avt:
                            updates['ex_avt_json'] = json.dumps(all_ex_avt, ensure_ascii=False)
                    
                    # æ‰§è¡Œæ›´æ–°
                    if updates:
                        set_clause = ', '.join([f"{k} = ?" for k in updates.keys()])
                        values = list(updates.values())
                        values.append(equip_id)
                        
                        cursor.execute(
                            f"UPDATE roles SET {set_clause} WHERE equip_id = ?",
                            values
                        )
                        
                        # # å•ç‹¬æ›´æ–° large_equip_desc_data è¡¨ä¸­çš„ all_new_point å­—æ®µ
                        # if parsed_desc.get('TA_iAllNewPoint'):
                        #     cursor.execute(
                        #         "UPDATE large_equip_desc_data SET all_new_point = ? WHERE equip_id = ?",
                        #         [parsed_desc.get('TA_iAllNewPoint'), equip_id]
                        #     )
                        #     self.logger.info(f"æ›´æ–°è§’è‰² {equip_id} çš„ä¹¾å…ƒä¸¹æ•°æ®: {parsed_desc.get('TA_iAllNewPoint')}")


                        # å•ç‹¬æ›´æ–° large_equip_desc_data è¡¨ä¸­çš„ sum_amount å­—æ®µ
                        if parsed_desc.get('pet'):
                            cursor.execute(
                                "UPDATE large_equip_desc_data SET pet = ? WHERE equip_id = ?",
                                [json.dumps(parsed_desc.get('pet'), ensure_ascii=False), equip_id]
                            )
                            self.logger.info(f"æ›´æ–°è§’è‰² {equip_id} çš„ pet æ•°æ®: {parsed_desc.get('pet')}")
                        updated_count += 1
                        self.logger.info(f"æ›´æ–°è§’è‰² {equip_id} çš„æ•°æ®æˆåŠŸ")
                
                except Exception as e:
                    self.logger.error(f"æ›´æ–°è§’è‰² {equip_id} æ—¶å‡ºé”™: {e}")
                    continue
            
            conn.commit()
            self.logger.info(f"æ•°æ®æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {updated_count} ä¸ªè§’è‰²")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°æ•°æ®æ—¶å‡ºé”™: {e}")
        finally:
            conn.close()
    
    def parse_large_equip_desc(self, large_desc):
        """
        è§£ælarge_equip_descå­—æ®µ
        
        Args:
            large_desc: åŸå§‹è£…å¤‡æè¿°æ•°æ®
        
        Returns:
            dict: è§£æåçš„æ•°æ®
        """
        if not large_desc or not isinstance(large_desc, str):
            return {}
        
        try:
            # ç§»é™¤å¯èƒ½çš„ç¼–ç æ ‡è®°
            clean_desc = large_desc.strip()
            if clean_desc.startswith('@') and clean_desc.endswith('@'):
                clean_desc = clean_desc[1:-1]
            
            # ä½¿ç”¨lpc_to_jsæ–¹æ³•è¿›è¡Œè§£æ
            js_format = self.lpc_helper.lpc_to_js(clean_desc, return_dict=False)
            if js_format:
                # ç„¶åç”¨js_evalè§£æJavaScriptæ ¼å¼å­—ç¬¦ä¸²
                parsed_data = self.lpc_helper.js_eval(js_format)
                if parsed_data and isinstance(parsed_data, dict) and len(parsed_data) > 0:
                    return parsed_data
            
            self.logger.warning(f"LPC->JSè§£æå¤±è´¥ï¼ŒåŸå§‹æ•°æ®å‰200å­—ç¬¦: {clean_desc[:200]}")
            return {}
            
        except Exception as e:
            self.logger.warning(f"è§£ælarge_equip_descå¤±è´¥: {e}")
            return {}
    
    def get_house_real_owner_name(self, owner_status):
        """è½¬æ¢æˆ¿å±‹çœŸå®æ‹¥æœ‰è€…çŠ¶æ€ä¸ºä¸­æ–‡åç§°"""
        return self.common_parser.get_house_real_owner_name(owner_status)
    
    def add_column_to_roles(self, column_name, column_type):
        """
        ä¸ºrolesè¡¨æ·»åŠ æ–°å­—æ®µ
        
        Args:
            column_name: å­—æ®µåç§°
            column_type: å­—æ®µç±»å‹ (å¦‚ 'TEXT', 'INTEGER', 'REAL' ç­‰)
            
        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        return self.add_column_to_table('roles', column_name, column_type)
    
    def add_column_to_table(self, table_name, column_name, column_type):
        """
        ä¸ºæŒ‡å®šè¡¨æ·»åŠ æ–°å­—æ®µ
        
        Args:
            table_name: è¡¨å
            column_name: å­—æ®µåç§°
            column_type: å­—æ®µç±»å‹ (å¦‚ 'TEXT', 'INTEGER', 'REAL' ç­‰)
            
        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                self.logger.error(f"è¡¨ {table_name} ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨
            cursor.execute(f"PRAGMA table_info({table_name})")
            existing_columns = [column[1] for column in cursor.fetchall()]
            
            if column_name in existing_columns:
                self.logger.warning(f"å­—æ®µ {column_name} åœ¨è¡¨ {table_name} ä¸­å·²å­˜åœ¨")
                return False
            
            # æ·»åŠ æ–°å­—æ®µ
            cursor.execute(f"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_type}")
            conn.commit()
            self.logger.info(f"æˆåŠŸæ·»åŠ å­—æ®µ {column_name} ({column_type}) åˆ°è¡¨ {table_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ å­—æ®µ {column_name} åˆ°è¡¨ {table_name} å¤±è´¥: {e}")
            return False
        finally:
            conn.close()
    
    def add_column_to_large_equip_desc(self, column_name, column_type):
        """
        ä¸ºlarge_equip_desc_dataè¡¨æ·»åŠ æ–°å­—æ®µçš„ä¾¿æ·æ–¹æ³•
        
        Args:
            column_name: å­—æ®µåç§°
            column_type: å­—æ®µç±»å‹ (å¦‚ 'TEXT', 'INTEGER', 'REAL' ç­‰)
            
        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        return self.add_column_to_table('large_equip_desc_data', column_name, column_type)
    
    def drop_column_from_table(self, table_name, column_name):
        """
        åˆ é™¤è¡¨ä¸­çš„å­—æ®µ
        
        Args:
            table_name: è¡¨å
            column_name: è¦åˆ é™¤çš„å­—æ®µå
            
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                self.logger.error(f"è¡¨ {table_name} ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            column_names = [col[1] for col in columns]
            
            if column_name not in column_names:
                self.logger.warning(f"å­—æ®µ {column_name} åœ¨è¡¨ {table_name} ä¸­ä¸å­˜åœ¨")
                return False
            
            # è·å–SQLiteç‰ˆæœ¬
            cursor.execute("SELECT sqlite_version()")
            version = cursor.fetchone()[0]
            version_parts = [int(x) for x in version.split('.')]
            
            # SQLite 3.35.0+ æ”¯æŒ ALTER TABLE DROP COLUMN
            supports_drop_column = (version_parts[0] > 3 or 
                                  (version_parts[0] == 3 and version_parts[1] > 35) or
                                  (version_parts[0] == 3 and version_parts[1] == 35 and version_parts[2] >= 0))
            
            if supports_drop_column:
                # ä½¿ç”¨æ–°è¯­æ³•ç›´æ¥åˆ é™¤å­—æ®µ
                self.logger.info(f"ä½¿ç”¨ ALTER TABLE DROP COLUMN åˆ é™¤å­—æ®µ {column_name}")
                cursor.execute(f"ALTER TABLE {table_name} DROP COLUMN {column_name}")
            else:
                # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ï¼šé‡å»ºè¡¨
                self.logger.info(f"ä½¿ç”¨è¡¨é‡å»ºæ–¹æ³•åˆ é™¤å­—æ®µ {column_name}")
                
                # è·å–é™¤äº†è¦åˆ é™¤å­—æ®µå¤–çš„æ‰€æœ‰å­—æ®µä¿¡æ¯
                remaining_columns = [col for col in columns if col[1] != column_name]
                
                if not remaining_columns:
                    self.logger.error(f"ä¸èƒ½åˆ é™¤è¡¨ {table_name} çš„æœ€åä¸€ä¸ªå­—æ®µ")
                    return False
                
                # æ„å»ºæ–°è¡¨çš„å­—æ®µå®šä¹‰
                column_defs = []
                column_names_new = []
                for col in remaining_columns:
                    col_name = col[1]
                    col_type = col[2]
                    col_notnull = col[3]
                    col_default = col[4]
                    col_pk = col[5]
                    
                    col_def = f"{col_name} {col_type}"
                    if col_pk:
                        col_def += " PRIMARY KEY"
                    if col_notnull and not col_pk:
                        col_def += " NOT NULL"
                    if col_default is not None:
                        col_def += f" DEFAULT {col_default}"
                    
                    column_defs.append(col_def)
                    column_names_new.append(col_name)
                
                # åˆ›å»ºä¸´æ—¶è¡¨
                temp_table = f"{table_name}_temp_{int(time.time())}"
                create_sql = f"CREATE TABLE {temp_table} ({', '.join(column_defs)})"
                cursor.execute(create_sql)
                
                # å¤åˆ¶æ•°æ®åˆ°ä¸´æ—¶è¡¨
                select_columns = ', '.join(column_names_new)
                cursor.execute(f"INSERT INTO {temp_table} ({select_columns}) SELECT {select_columns} FROM {table_name}")
                
                # åˆ é™¤åŸè¡¨
                cursor.execute(f"DROP TABLE {table_name}")
                
                # é‡å‘½åä¸´æ—¶è¡¨
                cursor.execute(f"ALTER TABLE {temp_table} RENAME TO {table_name}")
            
            conn.commit()
            self.logger.info(f"æˆåŠŸä»è¡¨ {table_name} åˆ é™¤å­—æ®µ {column_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä»è¡¨ {table_name} åˆ é™¤å­—æ®µ {column_name} å¤±è´¥: {e}")
            if 'conn' in locals():
                conn.rollback()
            return False
        finally:
            if 'conn' in locals():
                conn.close()
    
    def drop_column_from_roles(self, column_name):
        """
        ä»rolesè¡¨åˆ é™¤å­—æ®µçš„ä¾¿æ·æ–¹æ³•
        
        Args:
            column_name: è¦åˆ é™¤çš„å­—æ®µå
            
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        return self.drop_column_from_table('roles', column_name)
    
    def drop_column_from_large_equip_desc(self, column_name):
        """
        ä»large_equip_desc_dataè¡¨åˆ é™¤å­—æ®µçš„ä¾¿æ·æ–¹æ³•
        
        Args:
            column_name: è¦åˆ é™¤çš„å­—æ®µå
            
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        return self.drop_column_from_table('large_equip_desc_data', column_name)
    
    def update_equipment_features(self, equip_db_path=None):
        """
        æ›´æ–°è£…å¤‡æ•°æ®åº“ä¸­çš„ç‰¹å¾æ•°æ®
        
        ä½¿ç”¨ç‰¹å¾æå–å™¨é‡æ–°æå–çµé¥°è£…å¤‡çš„é™„åŠ å±æ€§ç‰¹å¾ï¼Œå¹¶è¦†ç›–agg_added_attrså­—æ®µ
        
        Args:
            equip_db_path: è£…å¤‡æ•°æ®åº“è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            
        Returns:
            int: æ›´æ–°çš„è£…å¤‡æ•°é‡
        """
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®åº“è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            if equip_db_path is None:
                project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                current_month = datetime.now().strftime('%Y%m')
                equip_db_path = os.path.join(project_root, 'data', current_month, f'cbg_equip_{current_month}.db')
            
            self.logger.info(f"å¼€å§‹æ›´æ–°è£…å¤‡æ•°æ®åº“: {equip_db_path}")
            
            # è¿æ¥è£…å¤‡æ•°æ®åº“
            conn = sqlite3.connect(equip_db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰çµé¥°è£…å¤‡æ•°æ® (kindid: 61, 62, 63, 64)
            cursor.execute("""
                SELECT eid, kindid, large_equip_desc, agg_added_attrs
                FROM equipments 
                WHERE kindid IN (61, 62, 63, 64)
                AND large_equip_desc IS NOT NULL 
                AND large_equip_desc != ''
            """)
            
            equipments = cursor.fetchall()
            self.logger.info(f"æ‰¾åˆ° {len(equipments)} ä¸ªçµé¥°è£…å¤‡éœ€è¦æ›´æ–°ç‰¹å¾")
            
            updated_count = 0
            error_count = 0
            
            for equip in equipments:
                try:
                    eid = equip[0]
                    kindid = equip[1]
                    large_equip_desc = equip[2]
                    old_agg_added_attrs = equip[3]
                    
                    # æ„å»ºè£…å¤‡æ•°æ®å­—å…¸
                    equip_data = {
                        'kindid': kindid,
                        'large_equip_desc': large_equip_desc
                    }
                    
                    # ä½¿ç”¨ç‰¹å¾æå–å™¨æå–é™„åŠ å±æ€§
                    added_attrs_features = self.lingshi_feature_extractor._extract_added_attrs_features(equip_data)
                    extracted_attrs = added_attrs_features.get('attrs', [])
                    
                    # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                    new_agg_added_attrs = json.dumps(extracted_attrs, ensure_ascii=False) if extracted_attrs else ''
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
                    if new_agg_added_attrs != old_agg_added_attrs:
                        # æ›´æ–°æ•°æ®åº“
                        cursor.execute(
                            "UPDATE equipments SET agg_added_attrs = ? WHERE eid = ?",
                            (new_agg_added_attrs, eid)
                        )
                        
                        updated_count += 1
                        
                        # è®°å½•è¯¦ç»†ä¿¡æ¯
                        if extracted_attrs:
                            attr_info = []
                            for attr in extracted_attrs:
                                attr_info.append(f"{attr['attr_type']}+{attr['attr_value']}")
                            self.logger.info(f"æ›´æ–°è£…å¤‡ {eid} (kindid:{kindid}): {', '.join(attr_info)}")
                        else:
                            self.logger.info(f"æ›´æ–°è£…å¤‡ {eid} (kindid:{kindid}): æ¸…ç©ºé™„åŠ å±æ€§")
                    else:
                        self.logger.debug(f"è£…å¤‡ {eid} (kindid:{kindid}): ç‰¹å¾æ— å˜åŒ–ï¼Œè·³è¿‡")
                        
                except Exception as e:
                    error_count += 1
                    self.logger.error(f"æ›´æ–°è£…å¤‡ {eid} ç‰¹å¾æ—¶å‡ºé”™: {e}")
                    continue
            
            # æäº¤æ›´æ”¹
            conn.commit()
            
            self.logger.info(f"è£…å¤‡ç‰¹å¾æ›´æ–°å®Œæˆ:")
            self.logger.info(f"  - æ€»è£…å¤‡æ•°: {len(equipments)}")
            self.logger.info(f"  - æˆåŠŸæ›´æ–°: {updated_count}")
            self.logger.info(f"  - é”™è¯¯æ•°é‡: {error_count}")
            
            return updated_count
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°è£…å¤‡ç‰¹å¾æ—¶å‡ºé”™: {e}")
            if 'conn' in locals():
                conn.rollback()
            return 0
        finally:
            if 'conn' in locals():
                conn.close()
    
    def update_equipment_features_batch(self, batch_size=100, equip_db_path=None):
        """
        æ‰¹é‡æ›´æ–°è£…å¤‡æ•°æ®åº“ä¸­çš„ç‰¹å¾æ•°æ®
        
        åˆ†æ‰¹å¤„ç†å¤§é‡æ•°æ®ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜
        
        Args:
            batch_size: æ¯æ‰¹å¤„ç†çš„è£…å¤‡æ•°é‡
            equip_db_path: è£…å¤‡æ•°æ®åº“è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            
        Returns:
            int: æ›´æ–°çš„è£…å¤‡æ•°é‡
        """
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®åº“è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            if equip_db_path is None:
                project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                current_month = datetime.now().strftime('%Y%m')
                equip_db_path = os.path.join(project_root, 'data', current_month, f'cbg_equip_{current_month}.db')
            
            self.logger.info(f"å¼€å§‹æ‰¹é‡æ›´æ–°è£…å¤‡æ•°æ®åº“: {equip_db_path}")
            
            # è¿æ¥è£…å¤‡æ•°æ®åº“
            conn = sqlite3.connect(equip_db_path)
            cursor = conn.cursor()
            
            # è·å–æ€»æ•°é‡
            cursor.execute("""
                SELECT COUNT(*) 
                FROM equipments 
                WHERE kindid IN (61, 62, 63, 64)
                AND large_equip_desc IS NOT NULL 
                AND large_equip_desc != ''
            """)
            total_count = cursor.fetchone()[0]
            
            self.logger.info(f"æ€»å…±éœ€è¦å¤„ç† {total_count} ä¸ªçµé¥°è£…å¤‡")
            
            updated_count = 0
            error_count = 0
            processed_count = 0
            
            # åˆ†æ‰¹å¤„ç†
            offset = 0
            while offset < total_count:
                # è·å–å½“å‰æ‰¹æ¬¡çš„è£…å¤‡
                cursor.execute("""
                    SELECT eid, kindid, large_equip_desc, agg_added_attrs
                    FROM equipments 
                    WHERE kindid IN (61, 62, 63, 64)
                    AND large_equip_desc IS NOT NULL 
                    AND large_equip_desc != ''
                    ORDER BY eid
                    LIMIT ? OFFSET ?
                """, (batch_size, offset))
                
                equipments = cursor.fetchall()
                
                if not equipments:
                    break
                
                self.logger.info(f"å¤„ç†ç¬¬ {offset//batch_size + 1} æ‰¹ï¼Œå…± {len(equipments)} ä¸ªè£…å¤‡")
                
                # å¤„ç†å½“å‰æ‰¹æ¬¡
                for equip in equipments:
                    try:
                        eid = equip[0]
                        kindid = equip[1]
                        large_equip_desc = equip[2]
                        old_agg_added_attrs = equip[3]
                        
                        # æ„å»ºè£…å¤‡æ•°æ®å­—å…¸
                        equip_data = {
                            'kindid': kindid,
                            'large_equip_desc': large_equip_desc
                        }
                        
                        # ä½¿ç”¨ç‰¹å¾æå–å™¨æå–é™„åŠ å±æ€§
                        added_attrs_features = self.lingshi_feature_extractor._extract_added_attrs_features(equip_data)
                        extracted_attrs = added_attrs_features.get('attrs', [])
                        
                        # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                        new_agg_added_attrs = json.dumps(extracted_attrs, ensure_ascii=False) if extracted_attrs else ''
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
                        if new_agg_added_attrs != old_agg_added_attrs:
                            # æ›´æ–°æ•°æ®åº“
                            cursor.execute(
                                "UPDATE equipments SET agg_added_attrs = ? WHERE eid = ?",
                                (new_agg_added_attrs, eid)
                            )
                            updated_count += 1
                        
                        processed_count += 1
                        
                        # æ¯å¤„ç†100ä¸ªè£…å¤‡æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        if processed_count % 100 == 0:
                            self.logger.info(f"å·²å¤„ç† {processed_count}/{total_count} ä¸ªè£…å¤‡ï¼Œæ›´æ–° {updated_count} ä¸ª")
                            
                    except Exception as e:
                        error_count += 1
                        self.logger.error(f"æ›´æ–°è£…å¤‡ {eid} ç‰¹å¾æ—¶å‡ºé”™: {e}")
                        continue
                
                # æäº¤å½“å‰æ‰¹æ¬¡çš„æ›´æ”¹
                conn.commit()
                
                # ç§»åŠ¨åˆ°ä¸‹ä¸€æ‰¹
                offset += batch_size
                
                # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
                time.sleep(0.1)
            
            self.logger.info(f"æ‰¹é‡è£…å¤‡ç‰¹å¾æ›´æ–°å®Œæˆ:")
            self.logger.info(f"  - æ€»è£…å¤‡æ•°: {total_count}")
            self.logger.info(f"  - å·²å¤„ç†: {processed_count}")
            self.logger.info(f"  - æˆåŠŸæ›´æ–°: {updated_count}")
            self.logger.info(f"  - é”™è¯¯æ•°é‡: {error_count}")
            
            return updated_count
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡æ›´æ–°è£…å¤‡ç‰¹å¾æ—¶å‡ºé”™: {e}")
            if 'conn' in locals():
                conn.rollback()
            return 0
        finally:
            if 'conn' in locals():
                conn.close()

def main():
    """ç®€å•çš„æµ‹è¯•å‡½æ•°"""
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    # è·å–å½“å‰æœˆä»½
    current_month = datetime.now().strftime('%Y%m')
    
    # è§’è‰²æ•°æ®åº“è·¯å¾„
    char_db_filename = f"empty_roles_{current_month}.db"
    char_db_path = os.path.join(project_root, 'data', char_db_filename)
    
    # è£…å¤‡æ•°æ®åº“è·¯å¾„
    equip_db_filename = f"cbg_equip_{current_month}.db"
    equip_db_path = os.path.join(project_root, 'data', equip_db_filename)
    
    # åˆ›å»ºæ›´æ–°å™¨
    updater = DataUpdater(char_db_path, logger)
    
    # æµ‹è¯•è£…å¤‡ç‰¹å¾æ›´æ–°åŠŸèƒ½
    print("ğŸ”§ å¼€å§‹æµ‹è¯•è£…å¤‡ç‰¹å¾æ›´æ–°åŠŸèƒ½...")
    
    # æ£€æŸ¥è£…å¤‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨
    if os.path.exists(equip_db_path):
        print(f"ğŸ“ æ‰¾åˆ°è£…å¤‡æ•°æ®åº“: {equip_db_path}")
        
        # ä½¿ç”¨æ‰¹é‡æ›´æ–°æ–¹æ³•ï¼ˆæ¨èç”¨äºå¤§é‡æ•°æ®ï¼‰
        print("ğŸš€ å¼€å§‹æ‰¹é‡æ›´æ–°è£…å¤‡ç‰¹å¾...")
        updated_count = updater.update_equipment_features_batch(batch_size=50, equip_db_path=equip_db_path)
        print(f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {updated_count} ä¸ªè£…å¤‡")
        
        # æˆ–è€…ä½¿ç”¨æ™®é€šæ›´æ–°æ–¹æ³•ï¼ˆé€‚ç”¨äºå°é‡æ•°æ®ï¼‰
        # print("ğŸš€ å¼€å§‹æ›´æ–°è£…å¤‡ç‰¹å¾...")
        # updated_count = updater.update_equipment_features(equip_db_path=equip_db_path)
        # print(f"âœ… æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {updated_count} ä¸ªè£…å¤‡")
        
    else:
        print(f"âŒ è£…å¤‡æ•°æ®åº“ä¸å­˜åœ¨: {equip_db_path}")
        print("è¯·å…ˆè¿è¡Œè£…å¤‡çˆ¬è™«è·å–æ•°æ®")
    
    # åŸæœ‰çš„è§’è‰²æ•°æ®æ›´æ–°åŠŸèƒ½ï¼ˆå·²æ³¨é‡Šï¼‰
    # updater.add_column_to_roles('sum_amount','INTEGER')
    # updater.add_column_to_table('large_equip_desc_data','pet','TEXT')
    # updater.update_role_data()
    # updater.drop_column_from_table('roles','sum_amount')

if __name__ == "__main__":
    main() 