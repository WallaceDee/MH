#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä»£ç†IPè½®æ¢ç³»ç»Ÿå®ç°
æä¾›å¤šç§ä»£ç†IPç®¡ç†å’Œè½®æ¢ç­–ç•¥
"""

import requests
import random
import time
import threading
import json
import logging
from urllib.parse import urlencode
from concurrent.futures import ThreadPoolExecutor, as_completed
import re
import os

class ProxyRotationManager:
    def __init__(self, proxy_sources=None, max_workers=3):
        """
        åˆå§‹åŒ–ä»£ç†IPè½®æ¢ç®¡ç†å™¨
        
        Args:
            proxy_sources: ä»£ç†IPæºé…ç½®
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œè€…æ•°é‡
        """
        self.proxy_pool = []
        self.max_workers = max_workers
        self.current_proxy_index = 0
        self.proxy_lock = threading.Lock()
        self.proxy_stats = {}
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = self._setup_logger()
        
        # åŠ è½½ä»£ç†IP
        if proxy_sources:
            self.load_proxies_from_sources(proxy_sources)
        else:
            self.load_proxies_from_file()
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('ProxyRotation')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def load_proxies_from_file(self, filename="proxy_list.txt"):
        """ä»æ–‡ä»¶åŠ è½½ä»£ç†åˆ—è¡¨"""
        try:
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            proxy_file_path = os.path.join(project_root, 'config', filename)
            
            with open(proxy_file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        proxy_info = self._parse_proxy_line(line)
                        if proxy_info:
                            self.proxy_pool.append(proxy_info)
            
            self.logger.info(f"ä»æ–‡ä»¶åŠ è½½äº† {len(self.proxy_pool)} ä¸ªä»£ç†IP")
            
        except FileNotFoundError:
            self.logger.warning(f"ä»£ç†IPæ–‡ä»¶ {filename} ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¤ºä¾‹æ–‡ä»¶...")
            self._create_sample_proxy_file(filename)
        except Exception as e:
            self.logger.error(f"åŠ è½½ä»£ç†IPæ–‡ä»¶å¤±è´¥: {e}")
    
    def _parse_proxy_line(self, line):
        """è§£æä»£ç†IPè¡Œ"""
        try:
            # æ”¯æŒå¤šç§æ ¼å¼
            # æ ¼å¼1: ip:port
            # æ ¼å¼2: protocol://ip:port
            # æ ¼å¼3: protocol://username:password@ip:port
            # æ ¼å¼4: ip:port:username:password
            
            if '://' in line:
                # å¸¦åè®®çš„æ ¼å¼
                if '@' in line:
                    # å¸¦è®¤è¯çš„æ ¼å¼: protocol://username:password@ip:port
                    protocol = line.split('://')[0]
                    auth_and_addr = line.split('://')[1]
                    auth, addr = auth_and_addr.split('@')
                    username, password = auth.split(':')
                    ip, port = addr.split(':')
                else:
                    # æ— è®¤è¯çš„æ ¼å¼: protocol://ip:port
                    protocol = line.split('://')[0]
                    addr = line.split('://')[1]
                    ip, port = addr.split(':')
                    username = password = None
            else:
                # æ— åè®®æ ¼å¼
                parts = line.split(':')
                if len(parts) == 2:
                    # ip:port
                    ip, port = parts
                    protocol = 'http'
                    username = password = None
                elif len(parts) == 4:
                    # ip:port:username:password
                    ip, port, username, password = parts
                    protocol = 'http'
                else:
                    return None
            
            return {
                'ip': ip,
                'port': int(port),
                'protocol': protocol,
                'username': username,
                'password': password,
                'url': self._build_proxy_url(protocol, ip, port, username, password),
                'success_count': 0,
                'failure_count': 0,
                'last_used': 0,
                'status': 'active',  # active, failed, banned
                'response_time': 0
            }
        except Exception as e:
            self.logger.warning(f"è§£æä»£ç†IPè¡Œå¤±è´¥: {line}, é”™è¯¯: {e}")
            return None
    
    def _build_proxy_url(self, protocol, ip, port, username=None, password=None):
        """æ„å»ºä»£ç†URL"""
        if username and password:
            return f"{protocol}://{username}:{password}@{ip}:{port}"
        else:
            return f"{protocol}://{ip}:{port}"
    
    def _create_sample_proxy_file(self, filename):
        """åˆ›å»ºç¤ºä¾‹ä»£ç†IPæ–‡ä»¶"""
        sample_content = """# ä»£ç†IPé…ç½®æ–‡ä»¶
# æ”¯æŒå¤šç§æ ¼å¼:
# 
# 1. ç®€å•æ ¼å¼: ip:port
# 127.0.0.1:8080
# 192.168.1.100:3128
# 
# 2. å¸¦åè®®: protocol://ip:port  
# http://127.0.0.1:8080
# https://192.168.1.100:3128
# socks5://127.0.0.1:1080
# 
# 3. å¸¦è®¤è¯: protocol://username:password@ip:port
# http://user:pass@127.0.0.1:8080
# 
# 4. å››æ®µæ ¼å¼: ip:port:username:password
# 127.0.0.1:8080:user:pass
# 
# è¯·æ·»åŠ ä½ çš„ä»£ç†IPåœ°å€
"""
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(sample_content)
            self.logger.info(f"å·²åˆ›å»ºç¤ºä¾‹ä»£ç†IPæ–‡ä»¶: {filename}")
        except Exception as e:
            self.logger.error(f"åˆ›å»ºç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {e}")
    
    def get_next_proxy(self):
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ä»£ç†IP"""
        with self.proxy_lock:
            if not self.proxy_pool:
                return None
            
            # è¿‡æ»¤å¯ç”¨çš„ä»£ç†
            active_proxies = [p for p in self.proxy_pool if p['status'] == 'active']
            
            if not active_proxies:
                self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ä»£ç†IP")
                return None
            
            # é€‰æ‹©ç­–ç•¥ï¼šè½®è¯¢ + æˆåŠŸç‡æƒé‡
            proxy = self._select_best_proxy(active_proxies)
            
            # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
            proxy['last_used'] = time.time()
            
            return proxy
    
    def _select_best_proxy(self, proxies):
        """é€‰æ‹©æœ€ä½³ä»£ç†IP"""
        # ç­–ç•¥1: ç®€å•è½®è¯¢
        if all(p['success_count'] == 0 and p['failure_count'] == 0 for p in proxies):
            return random.choice(proxies)
        
        # ç­–ç•¥2: åŸºäºæˆåŠŸç‡å’Œå“åº”æ—¶é—´çš„æƒé‡é€‰æ‹©
        best_proxy = None
        best_score = -1
        
        for proxy in proxies:
            total_requests = proxy['success_count'] + proxy['failure_count']
            if total_requests == 0:
                success_rate = 1.0
            else:
                success_rate = proxy['success_count'] / total_requests
            
            # å“åº”æ—¶é—´æƒé‡ï¼ˆè¶Šå¿«è¶Šå¥½ï¼‰
            time_weight = 1.0 / (proxy['response_time'] + 0.1)
            
            # ç»¼åˆè¯„åˆ†
            score = success_rate * 0.7 + time_weight * 0.3
            
            if score > best_score:
                best_score = score
                best_proxy = proxy
        
        return best_proxy
    
    def test_proxy(self, proxy, test_url="http://httpbin.org/ip", timeout=10):
        """æµ‹è¯•ä»£ç†IPæ˜¯å¦å¯ç”¨"""
        try:
            proxies = {
                'http': proxy['url'],
                'https': proxy['url']
            }
            
            start_time = time.time()
            response = requests.get(test_url, proxies=proxies, timeout=timeout)
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                proxy['response_time'] = response_time
                self.logger.info(f"ä»£ç† {proxy['ip']}:{proxy['port']} æµ‹è¯•æˆåŠŸï¼Œå“åº”æ—¶é—´: {response_time:.2f}s")
                return True
            else:
                self.logger.warning(f"ä»£ç† {proxy['ip']}:{proxy['port']} æµ‹è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.warning(f"ä»£ç† {proxy['ip']}:{proxy['port']} æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_all_proxies(self, test_url="http://httpbin.org/ip"):
        """æµ‹è¯•æ‰€æœ‰ä»£ç†IP"""
        self.logger.info("å¼€å§‹æµ‹è¯•æ‰€æœ‰ä»£ç†IP...")
        
        working_proxies = []
        failed_proxies = []
        
        for proxy in self.proxy_pool:
            if self.test_proxy(proxy, test_url):
                proxy['status'] = 'active'
                working_proxies.append(proxy)
            else:
                proxy['status'] = 'failed'
                failed_proxies.append(proxy)
        
        self.logger.info(f"ä»£ç†æµ‹è¯•å®Œæˆ: {len(working_proxies)} ä¸ªå¯ç”¨, {len(failed_proxies)} ä¸ªå¤±è´¥")
        return working_proxies, failed_proxies
    
    def mark_proxy_failed(self, proxy, reason="request_failed"):
        """æ ‡è®°ä»£ç†ä¸ºå¤±è´¥çŠ¶æ€"""
        with self.proxy_lock:
            proxy['failure_count'] += 1
            
            # å¦‚æœå¤±è´¥ç‡è¿‡é«˜ï¼Œæ ‡è®°ä¸ºå¤±è´¥çŠ¶æ€
            total_requests = proxy['success_count'] + proxy['failure_count']
            failure_rate = proxy['failure_count'] / total_requests
            
            if failure_rate > 0.5 and total_requests > 5:
                proxy['status'] = 'failed'
                self.logger.warning(f"ä»£ç† {proxy['ip']}:{proxy['port']} è¢«æ ‡è®°ä¸ºå¤±è´¥: {reason}")
    
    def mark_proxy_success(self, proxy):
        """æ ‡è®°ä»£ç†ä½¿ç”¨æˆåŠŸ"""
        with self.proxy_lock:
            proxy['success_count'] += 1
            if proxy['status'] == 'failed' and proxy['success_count'] > proxy['failure_count']:
                proxy['status'] = 'active'
                self.logger.info(f"ä»£ç† {proxy['ip']}:{proxy['port']} æ¢å¤æ´»è·ƒçŠ¶æ€")
    
    def get_proxy_stats(self):
        """è·å–ä»£ç†ä½¿ç”¨ç»Ÿè®¡"""
        stats = {
            'total_proxies': len(self.proxy_pool),
            'active_proxies': len([p for p in self.proxy_pool if p['status'] == 'active']),
            'failed_proxies': len([p for p in self.proxy_pool if p['status'] == 'failed']),
            'banned_proxies': len([p for p in self.proxy_pool if p['status'] == 'banned']),
        }
        return stats
    
    def show_proxy_status(self):
        """æ˜¾ç¤ºä»£ç†çŠ¶æ€"""
        stats = self.get_proxy_stats()
        
        print("\nğŸ“Š ä»£ç†IPçŠ¶æ€ç»Ÿè®¡")
        print("=" * 50)
        print(f"æ€»ä»£ç†æ•°: {stats['total_proxies']}")
        print(f"å¯ç”¨ä»£ç†: {stats['active_proxies']}")
        print(f"å¤±è´¥ä»£ç†: {stats['failed_proxies']}")
        print(f"è¢«å°ä»£ç†: {stats['banned_proxies']}")
        
        print("\nğŸ“‹ è¯¦ç»†ä»£ç†åˆ—è¡¨:")
        print("-" * 80)
        print(f"{'çŠ¶æ€':<8} {'åœ°å€':<20} {'æˆåŠŸ':<6} {'å¤±è´¥':<6} {'æˆåŠŸç‡':<8} {'å“åº”æ—¶é—´':<8}")
        print("-" * 80)
        
        for proxy in self.proxy_pool:
            total = proxy['success_count'] + proxy['failure_count']
            success_rate = proxy['success_count'] / total if total > 0 else 0
            status_emoji = {'active': 'âœ…', 'failed': 'âŒ', 'banned': 'ğŸš«'}.get(proxy['status'], 'â“')
            
            print(f"{status_emoji:<8} {proxy['ip']}:{proxy['port']:<12} "
                  f"{proxy['success_count']:<6} {proxy['failure_count']:<6} "
                  f"{success_rate:.1%:<8} {proxy['response_time']:.2f}s")

class CBGProxyCrawler:
    """æ•´åˆä»£ç†IPè½®æ¢çš„CBGçˆ¬è™«"""
    
    def __init__(self, proxy_manager, cookies_file="cookies.txt"):
        self.proxy_manager = proxy_manager
        self.logger = self._setup_logger()
        self.base_url = "https://xyq.cbg.163.com/cgi-bin/recommend.py"
        
        # åŠ è½½Cookie
        self.cookie = self._load_cookie(cookies_file)
        
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('CBGProxyCrawler')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _load_cookie(self, filename):
        """åŠ è½½Cookie"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            self.logger.error(f"åŠ è½½Cookieå¤±è´¥: {e}")
            return None
    
    def create_session_with_proxy(self, proxy=None):
        """åˆ›å»ºå¸¦ä»£ç†çš„ä¼šè¯"""
        session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'Referer': 'https://xyq.cbg.163.com/cgi-bin/xyq_overall_search.py',
        }
        
        if self.cookie:
            headers['Cookie'] = self.cookie
        
        session.headers.update(headers)
        
        # è®¾ç½®ä»£ç†
        if proxy:
            proxies = {
                'http': proxy['url'],
                'https': proxy['url']
            }
            session.proxies.update(proxies)
            self.logger.info(f"ä½¿ç”¨ä»£ç†: {proxy['ip']}:{proxy['port']}")
        
        return session
    
    def fetch_page_with_proxy_retry(self, page, max_retries=3):
        """ä½¿ç”¨ä»£ç†è½®æ¢è·å–é¡µé¢"""
        for attempt in range(max_retries):
            # è·å–ä»£ç†
            proxy = self.proxy_manager.get_next_proxy()
            if not proxy:
                self.logger.error(f"ç¬¬{page}é¡µ: æ²¡æœ‰å¯ç”¨çš„ä»£ç†IP")
                return None
            
            try:
                # åˆ›å»ºä¼šè¯
                session = self.create_session_with_proxy(proxy)
                
                # æ„å»ºè¯·æ±‚å‚æ•°
                params = {
                    'callback': f'Request.JSONP.request_map.request_{random.randint(0, 999)}',
                    '_': str(int(time.time() * 1000)),
                    'server_type': 3,
                    'act': 'recommd_by_role',
                    'page': page,
                    'count': 15,
                    'search_type': 'overall_search_role',
                    'view_loc': 'overall_search'
                }
                
                url = f"{self.base_url}?{urlencode(params)}"
                
                self.logger.info(f"ç¬¬{page}é¡µ ä½¿ç”¨ä»£ç† {proxy['ip']}:{proxy['port']}")
                
                # å‘é€è¯·æ±‚
                start_time = time.time()
                response = session.get(url, timeout=30)
                response_time = time.time() - start_time
                
                proxy['response_time'] = response_time
                
                if response.status_code == 200:
                    # æ£€æŸ¥å“åº”å†…å®¹
                    if self._is_valid_response(response.text):
                        self.proxy_manager.mark_proxy_success(proxy)
                        self.logger.info(f"ç¬¬{page}é¡µæˆåŠŸè·å– (ä»£ç†: {proxy['ip']}:{proxy['port']}, å“åº”æ—¶é—´: {response_time:.2f}s)")
                        return self._parse_jsonp_response(response.text)
                    else:
                        self.logger.warning(f"ç¬¬{page}é¡µå“åº”å¼‚å¸¸ï¼Œå¯èƒ½è¢«åçˆ¬è™«æ£€æµ‹")
                        self.proxy_manager.mark_proxy_failed(proxy, "invalid_response")
                
                elif response.status_code in [403, 429]:
                    self.logger.warning(f"ç¬¬{page}é¡µ: ä»£ç† {proxy['ip']}:{proxy['port']} è¢«é™åˆ¶ ({response.status_code})")
                    self.proxy_manager.mark_proxy_failed(proxy, f"http_{response.status_code}")
                
                else:
                    self.logger.warning(f"ç¬¬{page}é¡µ: HTTP {response.status_code}")
                    self.proxy_manager.mark_proxy_failed(proxy, f"http_{response.status_code}")
                
            except requests.exceptions.Timeout:
                self.logger.warning(f"ç¬¬{page}é¡µ: ä»£ç† {proxy['ip']}:{proxy['port']} è¶…æ—¶")
                self.proxy_manager.mark_proxy_failed(proxy, "timeout")
                
            except requests.exceptions.ConnectionError:
                self.logger.warning(f"ç¬¬{page}é¡µ: ä»£ç† {proxy['ip']}:{proxy['port']} è¿æ¥å¤±è´¥")
                self.proxy_manager.mark_proxy_failed(proxy, "connection_error")
                
            except Exception as e:
                self.logger.warning(f"ç¬¬{page}é¡µ: ä»£ç† {proxy['ip']}:{proxy['port']} å¼‚å¸¸: {e}")
                self.proxy_manager.mark_proxy_failed(proxy, "unknown_error")
            
            # é‡è¯•å‰ç­‰å¾…
            if attempt < max_retries - 1:
                wait_time = random.uniform(1, 3)
                self.logger.info(f"ç­‰å¾… {wait_time:.1f}ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        self.logger.error(f"ç¬¬{page}é¡µ: æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
        return None
    
    def _is_valid_response(self, text):
        """æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ­£å¸¸çš„JSONPç»“æ„
            if 'Request.JSONP.request_map.request_' in text and '({' in text and '})' in text:
                return True
            return False
        except Exception:
            return False
    
    def _parse_jsonp_response(self, text):
        """è§£æJSONPå“åº”"""
        try:
            match = re.search(r'Request\.JSONP\.request_map\.request_\d+\((.*)\)', text)
            if match:
                json_str = match.group(1)
                return json.loads(json_str)
        except Exception as e:
            self.logger.error(f"è§£æå“åº”å¤±è´¥: {e}")
        return None
    
    def parallel_crawl_with_proxy(self, start_page, end_page, delay_range=(1, 3)):
        """ä½¿ç”¨ä»£ç†å¹¶è¡Œçˆ¬å–"""
        self.logger.info(f"å¼€å§‹ä½¿ç”¨ä»£ç†å¹¶è¡Œçˆ¬å–ç¬¬{start_page}-{end_page}é¡µ")
        
        results = {}
        
        def crawl_single_page(page):
            """çˆ¬å–å•é¡µ"""
            result = self.fetch_page_with_proxy_retry(page)
            
            # éšæœºå»¶æ—¶
            delay = random.uniform(*delay_range)
            time.sleep(delay)
            
            return page, result
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=min(3, len([p for p in self.proxy_manager.proxy_pool if p['status'] == 'active']))) as executor:
            future_to_page = {executor.submit(crawl_single_page, page): page 
                             for page in range(start_page, end_page + 1)}
            
            for future in as_completed(future_to_page):
                page, result = future.result()
                results[page] = result
        
        successful_pages = len([r for r in results.values() if r])
        self.logger.info(f"å¹¶è¡Œçˆ¬å–å®Œæˆï¼ŒæˆåŠŸè·å– {successful_pages} é¡µæ•°æ®")
        
        return results

def demo_proxy_rotation():
    """æ¼”ç¤ºä»£ç†IPè½®æ¢åŠŸèƒ½"""
    print("ğŸŒ ä»£ç†IPè½®æ¢æ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨
    proxy_manager = ProxyRotationManager()
    
    if not proxy_manager.proxy_pool:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„ä»£ç†IPï¼Œè¯·åœ¨ proxy_list.txt ä¸­æ·»åŠ ä»£ç†IP")
        print("\nğŸ“ ä»£ç†IPæ ¼å¼ç¤ºä¾‹:")
        print("http://127.0.0.1:8080")
        print("192.168.1.100:3128") 
        print("socks5://user:pass@127.0.0.1:1080")
        return
    
    # 2. æµ‹è¯•æ‰€æœ‰ä»£ç†
    print("\nğŸ” æµ‹è¯•ä»£ç†IPå¯ç”¨æ€§...")
    working_proxies, failed_proxies = proxy_manager.test_all_proxies()
    
    if not working_proxies:
        print("âŒ æ‰€æœ‰ä»£ç†IPéƒ½ä¸å¯ç”¨")
        return
    
    # 3. æ˜¾ç¤ºä»£ç†çŠ¶æ€
    proxy_manager.show_proxy_status()
    
    # 4. æ¼”ç¤ºCBGçˆ¬è™«é›†æˆ
    print("\nğŸš€ æµ‹è¯•CBGçˆ¬è™«é›†æˆ...")
    crawler = CBGProxyCrawler(proxy_manager)
    
    # æµ‹è¯•å•é¡µçˆ¬å–
    result = crawler.fetch_page_with_proxy_retry(1)
    if result:
        print("âœ… å•é¡µçˆ¬å–æˆåŠŸ")
    else:
        print("âŒ å•é¡µçˆ¬å–å¤±è´¥")
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆä»£ç†ç»Ÿè®¡:")
    proxy_manager.show_proxy_status()

if __name__ == "__main__":
    demo_proxy_rotation() 