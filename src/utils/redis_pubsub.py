#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Rediså‘å¸ƒ/è®¢é˜…å·¥å…·ç±»
ç”¨äºè§£å†³è·¨è¿›ç¨‹æ•°æ®åŒæ­¥é—®é¢˜
"""

import json
import redis
import logging
from typing import Dict, Any, Optional, Callable
from datetime import datetime
import threading
import time
import pandas as pd


class RedisPubSub:
    """Rediså‘å¸ƒ/è®¢é˜…å·¥å…·ç±»"""
    
    def __init__(self, redis_client: Optional[redis.Redis] = None):
        """
        åˆå§‹åŒ–Rediså‘å¸ƒ/è®¢é˜…
        
        Args:
            redis_client: Rediså®¢æˆ·ç«¯å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°å®ä¾‹
        """
        self.redis_client = redis_client or self._create_redis_client()
        self.pubsub = self.redis_client.pubsub()
        self.subscribers = {}  # å­˜å‚¨è®¢é˜…è€…å›è°ƒå‡½æ•°åˆ—è¡¨ {channel: [callback1, callback2, ...]}
        self.subscribe_thread = None
        self.running = False
        self.logger = logging.getLogger(__name__)
        self.reconnect_attempts = 0  # é‡è¿å°è¯•æ¬¡æ•°
        self.max_reconnect_attempts = 10  # æœ€å¤§é‡è¿æ¬¡æ•°
        self.reconnect_delay = 1  # åˆå§‹é‡è¿å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.max_reconnect_delay = 60  # æœ€å¤§é‡è¿å»¶è¿Ÿï¼ˆç§’ï¼‰
        
    def _create_redis_client(self) -> redis.Redis:
        """åˆ›å»ºRediså®¢æˆ·ç«¯"""
        try:
            # ä½¿ç”¨ä¸redis_cache.pyç›¸åŒçš„è¿œç¨‹Redisé…ç½®
            return redis.Redis(
                host='47.86.33.98',
                port=6379,
                db=0,
                password='447363121',
                decode_responses=True,
                socket_connect_timeout=10,
                socket_timeout=30,
                retry_on_timeout=True
            )
        except Exception as e:
            self.logger.error(f"åˆ›å»ºRediså®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise
    
    def publish(self, channel: str, message: Dict[str, Any]) -> bool:
        """
        å‘å¸ƒæ¶ˆæ¯åˆ°æŒ‡å®šé¢‘é“
        
        Args:
            channel: é¢‘é“åç§°
            message: æ¶ˆæ¯å†…å®¹
            
        Returns:
            bool: æ˜¯å¦å‘å¸ƒæˆåŠŸ
        """
        try:
            # æ·»åŠ æ—¶é—´æˆ³
            message['timestamp'] = datetime.now().isoformat()
            message['publisher'] = 'spider'
            
            # åºåˆ—åŒ–æ¶ˆæ¯
            message_str = json.dumps(message, ensure_ascii=False)
            
            # å‘å¸ƒæ¶ˆæ¯
            result = self.redis_client.publish(channel, message_str)
            
            self.logger.info(f"ğŸ“¢ å‘å¸ƒæ¶ˆæ¯åˆ°é¢‘é“ {channel}: {message.get('type', 'unknown')}")
            return result > 0
            
        except Exception as e:
            self.logger.error(f"å‘å¸ƒæ¶ˆæ¯å¤±è´¥: {e}")
            return False
    
    def publish_with_dataframe(self, channel: str, message: Dict[str, Any], dataframe: pd.DataFrame) -> bool:
        """
        å‘å¸ƒåŒ…å«DataFrameæ•°æ®çš„æ¶ˆæ¯åˆ°æŒ‡å®šé¢‘é“
        
        Args:
            channel: é¢‘é“åç§°
            message: æ¶ˆæ¯å†…å®¹
            dataframe: è¦å‘é€çš„DataFrameæ•°æ®
            
        Returns:
            bool: æ˜¯å¦å‘å¸ƒæˆåŠŸ
        """
        try:
            import pickle
            import base64
            
            # æ·»åŠ æ—¶é—´æˆ³
            message['timestamp'] = datetime.now().isoformat()
            message['publisher'] = 'spider'
            message['has_dataframe'] = True
            
            # åºåˆ—åŒ–DataFrame
            dataframe_bytes = pickle.dumps(dataframe)
            dataframe_b64 = base64.b64encode(dataframe_bytes).decode('utf-8')
            message['dataframe_data'] = dataframe_b64
            message['dataframe_shape'] = dataframe.shape
            message['dataframe_columns'] = dataframe.columns.tolist()
            
            # åºåˆ—åŒ–æ¶ˆæ¯
            message_str = json.dumps(message, ensure_ascii=False)
            
            # å‘å¸ƒæ¶ˆæ¯
            result = self.redis_client.publish(channel, message_str)
            
            self.logger.info(f"ğŸ“¢ å‘å¸ƒDataFrameæ¶ˆæ¯åˆ°é¢‘é“ {channel}: {message.get('type', 'unknown')}, æ•°æ®é‡: {len(dataframe)} æ¡")
            return result > 0
            
        except Exception as e:
            self.logger.error(f"å‘å¸ƒDataFrameæ¶ˆæ¯å¤±è´¥: {e}")
            return False
    
    def subscribe(self, channel: str, callback: Callable[[Dict[str, Any]], None]) -> bool:
        """
        è®¢é˜…æŒ‡å®šé¢‘é“ï¼ˆæ”¯æŒå¤šä¸ªè®¢é˜…è€…ï¼‰
        
        Args:
            channel: é¢‘é“åç§°
            callback: æ¶ˆæ¯å¤„ç†å›è°ƒå‡½æ•°
            
        Returns:
            bool: æ˜¯å¦è®¢é˜…æˆåŠŸ
        """
        try:
            # å¦‚æœé¢‘é“ä¸å­˜åœ¨ï¼Œåˆ›å»ºå›è°ƒåˆ—è¡¨
            if channel not in self.subscribers:
                self.subscribers[channel] = []
                self.pubsub.subscribe(channel)
                self.logger.info(f"ğŸ“¡ è®¢é˜…é¢‘é“: {channel} (é¦–æ¬¡è®¢é˜…)")
            
            # æ·»åŠ å›è°ƒåˆ°åˆ—è¡¨ï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
            if callback not in self.subscribers[channel]:
                self.subscribers[channel].append(callback)
                self.logger.info(f"ğŸ“¡ æ·»åŠ å›è°ƒåˆ°é¢‘é“: {channel} (å…± {len(self.subscribers[channel])} ä¸ªè®¢é˜…è€…)")
            else:
                self.logger.debug(f"ğŸ“¡ å›è°ƒå·²å­˜åœ¨ï¼Œè·³è¿‡: {channel}")
            
            # å¯åŠ¨è®¢é˜…çº¿ç¨‹
            if not self.running:
                self._start_subscribe_thread()
            
            return True
            
        except Exception as e:
            self.logger.error(f"è®¢é˜…é¢‘é“å¤±è´¥: {e}")
            return False
    
    def unsubscribe(self, channel: str) -> bool:
        """
        å–æ¶ˆè®¢é˜…æŒ‡å®šé¢‘é“
        
        Args:
            channel: é¢‘é“åç§°
            
        Returns:
            bool: æ˜¯å¦å–æ¶ˆè®¢é˜…æˆåŠŸ
        """
        try:
            if channel in self.subscribers:
                del self.subscribers[channel]
                self.pubsub.unsubscribe(channel)
                self.logger.info(f"ğŸ“¡ å–æ¶ˆè®¢é˜…é¢‘é“: {channel}")
                return True
            return False
            
        except Exception as e:
            self.logger.error(f"å–æ¶ˆè®¢é˜…é¢‘é“å¤±è´¥: {e}")
            return False
    
    def _start_subscribe_thread(self):
        """å¯åŠ¨è®¢é˜…çº¿ç¨‹"""
        if self.subscribe_thread and self.subscribe_thread.is_alive():
            return
        
        self.running = True
        self.subscribe_thread = threading.Thread(target=self._subscribe_loop, daemon=True)
        self.subscribe_thread.start()
        self.logger.info("ğŸ“¡ å¯åŠ¨Redisè®¢é˜…çº¿ç¨‹")
    
    def _subscribe_loop(self):
        """è®¢é˜…å¾ªç¯ï¼Œæ”¯æŒè‡ªåŠ¨é‡è¿"""
        while self.running:
            try:
                # è·å–æ¶ˆæ¯ï¼Œè¶…æ—¶1ç§’
                message = self.pubsub.get_message(timeout=1.0)
                
                if message and message['type'] == 'message':
                    self._handle_message(message)
                    # æ”¶åˆ°æ¶ˆæ¯è¯´æ˜è¿æ¥æ­£å¸¸ï¼Œé‡ç½®é‡è¿è®¡æ•°
                    if self.reconnect_attempts > 0:
                        self.reconnect_attempts = 0
                        self.reconnect_delay = 1
                    
            except redis.ConnectionError as e:
                self.logger.error(f"Redisè¿æ¥é”™è¯¯: {e}")
                self._reconnect()
            except Exception as e:
                error_msg = str(e)
                if "Connection closed" in error_msg or "ConnectionError" in error_msg:
                    self.logger.error(f"Redisè¿æ¥æ–­å¼€: {e}")
                    self._reconnect()
                else:
                    self.logger.error(f"è®¢é˜…å¾ªç¯é”™è¯¯: {e}")
                    time.sleep(1)
    
    def _handle_message(self, message):
        """å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯ï¼ˆè°ƒç”¨æ‰€æœ‰è®¢é˜…è€…çš„å›è°ƒï¼‰"""
        try:
            channel = message['channel']
            data = message['data']
            
            # è§£ææ¶ˆæ¯
            message_data = json.loads(data)
            
            # å¦‚æœæ¶ˆæ¯åŒ…å«DataFrameæ•°æ®ï¼Œè¿›è¡Œååºåˆ—åŒ–
            if message_data.get('has_dataframe', False):
                try:
                    import pickle
                    import base64
                    
                    dataframe_b64 = message_data.get('dataframe_data')
                    if dataframe_b64:
                        dataframe_bytes = base64.b64decode(dataframe_b64)
                        dataframe = pickle.loads(dataframe_bytes)
                        message_data['dataframe'] = dataframe
                        
                        self.logger.info(f"ğŸ“¨ æˆåŠŸååºåˆ—åŒ–DataFrame: {dataframe.shape}")
                        
                except Exception as e:
                    self.logger.error(f"ååºåˆ—åŒ–DataFrameå¤±è´¥: {e}")
                    message_data['dataframe'] = None
            
            # è°ƒç”¨æ‰€æœ‰è®¢é˜…è€…çš„å›è°ƒå‡½æ•°
            if channel in self.subscribers:
                callbacks = self.subscribers[channel]
                if isinstance(callbacks, list):
                    # æ–°ç‰ˆæœ¬ï¼šæ”¯æŒå¤šä¸ªè®¢é˜…è€…
                    for callback in callbacks:
                        try:
                            callback(message_data)
                        except Exception as e:
                            self.logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
                else:
                    # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå•ä¸ªå›è°ƒ
                    try:
                        callbacks(message_data)
                    except Exception as e:
                        self.logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
                
        except Exception as e:
            self.logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
    
    def _reconnect(self):
        """é‡æ–°è¿æ¥Rediså¹¶æ¢å¤è®¢é˜…"""
        if self.reconnect_attempts >= self.max_reconnect_attempts:
            self.logger.error(f"è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•° ({self.max_reconnect_attempts})ï¼Œåœæ­¢é‡è¿")
            self.running = False
            return
        
        self.reconnect_attempts += 1
        
        # è®¡ç®—é€€é¿å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼‰
        delay = min(self.reconnect_delay * (2 ** (self.reconnect_attempts - 1)), self.max_reconnect_delay)
        self.logger.info(f"å°è¯•é‡è¿ Redis (ç¬¬ {self.reconnect_attempts}/{self.max_reconnect_attempts} æ¬¡)ï¼Œç­‰å¾… {delay} ç§’...")
        time.sleep(delay)
        
        try:
            # å…³é—­æ—§çš„ pubsub è¿æ¥
            try:
                self.pubsub.close()
            except:
                pass
            
            # é‡æ–°åˆ›å»º Redis å®¢æˆ·ç«¯
            self.redis_client = self._create_redis_client()
            self.pubsub = self.redis_client.pubsub()
            
            # é‡æ–°è®¢é˜…æ‰€æœ‰é¢‘é“
            if self.subscribers:
                self.logger.info(f"é‡æ–°è®¢é˜… {len(self.subscribers)} ä¸ªé¢‘é“...")
                for channel in self.subscribers.keys():
                    self.pubsub.subscribe(channel)
                    self.logger.info(f"ğŸ“¡ å·²é‡æ–°è®¢é˜…é¢‘é“: {channel}")
            
            self.logger.info("Redis é‡è¿æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"Redis é‡è¿å¤±è´¥: {e}")
            # ç»§ç»­å¾ªç¯ä¼šåœ¨ä¸‹æ¬¡è·å–æ¶ˆæ¯æ—¶å†æ¬¡å°è¯•é‡è¿
    
    def stop(self):
        """åœæ­¢è®¢é˜…"""
        self.running = False
        if self.subscribe_thread:
            self.subscribe_thread.join(timeout=2)
        try:
            self.pubsub.close()
        except:
            pass
        self.logger.info("ğŸ“¡ åœæ­¢Redisè®¢é˜…")


# å…¨å±€å®ä¾‹
_redis_pubsub_instance = None


def get_redis_pubsub() -> RedisPubSub:
    """è·å–å…¨å±€Rediså‘å¸ƒ/è®¢é˜…å®ä¾‹"""
    global _redis_pubsub_instance
    if _redis_pubsub_instance is None:
        _redis_pubsub_instance = RedisPubSub()
    return _redis_pubsub_instance


# æ¶ˆæ¯ç±»å‹å¸¸é‡
class MessageType:
    """æ¶ˆæ¯ç±»å‹å¸¸é‡"""
    EQUIPMENT_DATA_SAVED = "equipment_data_saved"
    EQUIPMENT_CACHE_UPDATED = "equipment_cache_updated"
    EQUIPMENT_CACHE_REFRESHED = "equipment_cache_refreshed"
    PET_DATA_SAVED = "pet_data_saved"
    PET_CACHE_UPDATED = "pet_cache_updated"
    PET_CACHE_REFRESHED = "pet_cache_refreshed"


# é¢‘é“åç§°å¸¸é‡
class Channel:
    """é¢‘é“åç§°å¸¸é‡"""
    EQUIPMENT_UPDATES = "equipment_updates"
    PET_UPDATES = "pet_updates"
    CACHE_UPDATES = "cache_updates"
