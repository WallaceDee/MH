from datetime import datetime
from typing import Dict, Any, List, Optional, Union, Tuple
import logging
import pandas as pd
import os

# ä»é…ç½®æ–‡ä»¶åŠ è½½å¸¸é‡
from .constant import (
    get_agility_suits, get_magic_suits, get_high_value_suits,
    get_precise_filter_suits, get_high_value_effects, get_important_effects,
    get_high_value_simple_levels, get_simple_effect_id,
    get_low_value_special_skills, get_low_value_effects
)

# å¥—è£…æ•ˆæœIDå¸¸é‡å®šä¹‰
# é«˜ä»·å€¼å¥—è£…
AGILITY_SUITS = get_agility_suits()  # æ•æ·å¥—è£…
MAGIC_SUITS = get_magic_suits()  # é­”åŠ›å¥—è£…
HIGH_VALUE_SUITS = get_high_value_suits()  # åˆå¹¶é«˜ä»·å€¼å¥—è£…

# ç²¾ç¡®ç­›é€‰å¥—è£…ï¼ˆå…è®¸ç²¾ç¡®ç­›é€‰çš„å¥—è£…æ•ˆæœï¼‰
PRECISE_FILTER_SUITS = get_precise_filter_suits()  # å®šå¿ƒæœ¯ã€å˜èº«ã€ç¢æ˜Ÿè¯€ã€å¤©ç¥æŠ¤ä½“ã€æ»¡å¤©èŠ±é›¨ã€æµªæ¶Œ

# é«˜ä»·å€¼ç‰¹æ•ˆ
HIGH_VALUE_EFFECTS = get_high_value_effects()  # æ— çº§åˆ«ï¼Œæ„¤æ€’ï¼Œæ°¸ä¸ç£¨æŸ é«˜ä»·å€¼ç‰¹æ•ˆ
IMPORTANT_EFFECTS = get_important_effects()  # ç›¸ä¼¼åº¦è®¡ç®—ä¸­é‡è¦çš„ç‰¹æ•ˆ

# é«˜ä»·å€¼ç®€æ˜“è£…å¤‡ç­‰çº§
HIGH_VALUE_EQUIP_LEVELS = get_high_value_simple_levels()  # é«˜ä»·å€¼ç®€æ˜“è£…å¤‡ç­‰çº§
SIMPLE_EFFECT_ID = get_simple_effect_id()  # ç®€æ˜“è£…å¤‡ç‰¹æ•ˆç¼–å·

# ä½ä»·å€¼ç‰¹æŠ€
LOW_VALUE_SPECIAL_SKILLS = get_low_value_special_skills()
# ä½ä»·å€¼ç‰¹æ•ˆ
LOW_VALUE_EFFECTS = get_low_value_effects()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œè§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜
current_dir = os.path.dirname(os.path.abspath(__file__))

try:
    from ...feature_extractor.equip_feature_extractor import EquipFeatureExtractor
    from src.database import db
    from src.models.equipment import Equipment
    from sqlalchemy import and_, or_, func, text
except ImportError:
    try:
        from src.evaluator.feature_extractor.equip_feature_extractor import EquipFeatureExtractor
        from src.database import db
        from src.models.equipment import Equipment
        from sqlalchemy import and_, or_, func, text
    except ImportError:
        # å¦‚æœéƒ½å¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„å ä½ç¬¦
        class EquipFeatureExtractor:
            def __init__(self):
                pass

            def extract_features(self, equip_data):
                return {}


class EquipMarketDataCollector:
    """è£…å¤‡å¸‚åœºæ•°æ®é‡‡é›†å™¨ - ä»æ•°æ®åº“ä¸­è·å–å’Œå¤„ç†è£…å¤‡å¸‚åœºæ•°æ®"""

    _instance = None  # å•ä¾‹å®ä¾‹
    _lock = None  # çº¿ç¨‹é”ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼å®ç°"""
        import threading
        if cls._lock is None:
            cls._lock = threading.Lock()
            
        with cls._lock:
            if cls._instance is None:
                instance = super(EquipMarketDataCollector, cls).__new__(cls)
                cls._instance = instance
                # æ ‡è®°å®ä¾‹æ˜¯å¦å·²åˆå§‹åŒ–ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
                instance._initialized = False
                print("åˆ›å»ºæ–°çš„ EquipMarketDataCollector å•ä¾‹å®ä¾‹")
            else:
                print("ä½¿ç”¨ç°æœ‰çš„ EquipMarketDataCollector å•ä¾‹å®ä¾‹")
            
            return cls._instance

    def __init__(self):
        """
        åˆå§‹åŒ–è£…å¤‡å¸‚åœºæ•°æ®é‡‡é›†å™¨ - æ”¯æŒRediså…¨é‡ç¼“å­˜ï¼ˆå•ä¾‹æ¨¡å¼ä¸‹åªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
        """
        # é¿å…é‡å¤åˆå§‹åŒ–
        if hasattr(self, '_initialized') and self._initialized:
            return
            
        self.feature_extractor = EquipFeatureExtractor()
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–Redisç¼“å­˜
        try:
            from src.utils.redis_cache import get_redis_cache
            self.redis_cache = get_redis_cache()
            if self.redis_cache and self.redis_cache.is_available():
                self.logger.info("Redisç¼“å­˜åˆå§‹åŒ–æˆåŠŸï¼Œå°†ä½¿ç”¨Rediså…¨é‡ç¼“å­˜æ¨¡å¼")
                print("è£…å¤‡æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–ï¼Œä½¿ç”¨Rediså…¨é‡ç¼“å­˜æ¨¡å¼")
            else:
                self.redis_cache = None
                print("è£…å¤‡æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–ï¼ŒRedisä¸å¯ç”¨ï¼Œä½¿ç”¨MySQLæ•°æ®åº“")
        except Exception as e:
            self.logger.warning(f"Redisç¼“å­˜åˆå§‹åŒ–å¤±è´¥: {e}")
            self.redis_cache = None
            print("è£…å¤‡æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–ï¼ŒRedisåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨MySQLæ•°æ®åº“")
        
        # å…¨é‡ç¼“å­˜ç›¸å…³å±æ€§
        self._full_cache_key = "equipment_market_data_full"
        self._cache_ttl_hours = -1  # æ°¸ä¸è¿‡æœŸï¼Œåªèƒ½æ‰‹åŠ¨åˆ·æ–°
        self._full_data_cache = None  # å†…å­˜ä¸­çš„å…¨é‡æ•°æ®ç¼“å­˜
        
        # è¿›åº¦è·Ÿè¸ªç›¸å…³å±æ€§
        self._refresh_status = "idle"  # idle, running, completed, error
        self._refresh_progress = 0  # 0-100
        self._refresh_message = ""
        self._refresh_start_time = None
        self._refresh_total_records = 0
        self._refresh_processed_records = 0
        self._refresh_current_batch = 0
        self._refresh_total_batches = 0
        
        self._initialized = True
        cache_mode = "æ°¸ä¸è¿‡æœŸæ¨¡å¼" if self._cache_ttl_hours == -1 else f"{self._cache_ttl_hours}å°æ—¶è¿‡æœŸ"
        print(f"è£…å¤‡å¸‚åœºæ•°æ®é‡‡é›†å™¨å•ä¾‹åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒRediså…¨é‡ç¼“å­˜ï¼ˆ{cache_mode}ï¼‰")

#TODO: åŠ è½½å®Œåæ²¡æœ‰èµ‹å€¼ï¼Œæ²¡æœ‰ç”¨ç®¡é“è®¾ç½®redis
    def _load_full_data_to_redis(self, force_refresh: bool = False) -> bool:
        """
        åŠ è½½å…¨é‡è£…å¤‡æ•°æ®åˆ°Redis - å‚è€ƒè§’è‰²æ¨¡å—çš„æ‰¹æ¬¡å¤„ç†å’Œè¿›åº¦è·Ÿè¸ª
        
        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if not self.redis_cache:
            return False
            
        try:
            import time
            from datetime import datetime
            
            # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
            self._refresh_status = "running"
            self._refresh_progress = 0
            self._refresh_message = "å¼€å§‹åŠ è½½è£…å¤‡æ•°æ®..."
            self._refresh_start_time = datetime.now()
            self._refresh_processed_records = 0
            self._refresh_current_batch = 0
            
            start_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜ä¸”ä¸éœ€è¦å¼ºåˆ¶åˆ·æ–°
            if not force_refresh:
                self._refresh_message = "æ£€æŸ¥ç°æœ‰ç¼“å­˜..."
                self._refresh_progress = 5
                
                try:
                    print("ğŸ” å¼€å§‹æ£€æŸ¥Redisç¼“å­˜...")
                    cached_data = self.redis_cache.get_chunked_data(self._full_cache_key)
                    print(f"ğŸ” Redisç¼“å­˜æ£€æŸ¥å®Œæˆï¼Œç»“æœ: {cached_data is not None}")
                    
                    if cached_data is not None and not cached_data.empty:
                        print(f"Rediså…¨é‡ç¼“å­˜å·²å­˜åœ¨ï¼Œæ•°æ®é‡: {len(cached_data)} æ¡")
                        # æ­£ç¡®è®¾ç½®çŠ¶æ€ä¿¡æ¯
                        self._refresh_status = "completed"
                        self._refresh_progress = 100
                        self._refresh_message = "ä½¿ç”¨ç°æœ‰ç¼“å­˜"
                        self._refresh_total_records = len(cached_data)
                        self._refresh_processed_records = len(cached_data)
                        self._refresh_total_batches = 1
                        self._refresh_current_batch = 1
                        # å°†æ•°æ®åŠ è½½åˆ°å†…å­˜ç¼“å­˜
                        self._full_data_cache = cached_data
                        return True
                    else:
                        print("Redisç¼“å­˜ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå°†é‡æ–°åŠ è½½æ•°æ®")
                except Exception as e:
                    print(f"æ£€æŸ¥Redisç¼“å­˜æ—¶å‡ºé”™: {e}")
                    self._refresh_message = f"æ£€æŸ¥ç¼“å­˜å¤±è´¥: {str(e)}"
                    # ç»§ç»­æ‰§è¡Œé‡æ–°åŠ è½½
            
            print("ğŸ§ª [ä¸´æ—¶æµ‹è¯•æ¨¡å¼] å¼€å§‹ä»MySQLåŠ è½½è£…å¤‡æ•°æ®åˆ°Redis...")
            
            # ä»æ•°æ®åº“åŠ è½½å…¨é‡æ•°æ®
            from src.database import db
            from src.models.equipment import Equipment
            from flask import current_app
            
            # ç¡®ä¿åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­
            if not current_app:
                raise RuntimeError("å¿…é¡»åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œæ•°æ®åº“æ“ä½œ")
            
            # è·å–æ€»è®°å½•æ•°
            self._refresh_message = "ç»Ÿè®¡æ•°æ®æ€»é‡..."
            self._refresh_progress = 10
            
            # ä¸´æ—¶æµ‹è¯•ï¼šé™åˆ¶åŠ è½½1000æ¡æ•°æ®
            full_count = db.session.query(Equipment).count()
            total_count = full_count  # ä¸´æ—¶é™åˆ¶ä¸º1000æ¡
            print(f"è£…å¤‡æ€»è®°å½•æ•°: {full_count}ï¼Œæœ¬æ¬¡æµ‹è¯•åŠ è½½: {total_count} æ¡")
            
            # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼ˆå‚è€ƒè§’è‰²æ¨¡å—ï¼‰
            if total_count > 50000:
                batch_size = 300   # å¤§æ•°æ®é›†ï¼šå°æ‰¹æ¬¡
            elif total_count > 20000:
                batch_size = 500   # ä¸­ç­‰æ•°æ®é›†
            elif total_count > 5000:
                batch_size = 800   # ä¸­å°æ•°æ®é›†
            else:
                batch_size = 300   # å°æ•°æ®é›†
            
            total_batches = (total_count + batch_size - 1) // batch_size
            self._refresh_total_records = total_count
            self._refresh_total_batches = total_batches
            
            print(f"å°†åˆ† {total_batches} æ‰¹å¤„ç†ï¼Œæ¯æ‰¹ {batch_size} æ¡")
            
            # åˆ†æ‰¹åŠ è½½æ•°æ®
            all_data = []
            offset = 0
            
            for batch_num in range(total_batches):
                # æ›´æ–°è¿›åº¦
                self._refresh_current_batch = batch_num + 1
                batch_progress = 10 + int(((batch_num + 1) / total_batches) * 80)  # 10-90%çš„è¿›åº¦èŒƒå›´
                self._refresh_progress = min(batch_progress, 90)
                self._refresh_message = f"å¤„ç†ç¬¬ {batch_num + 1}/{total_batches} æ‰¹è£…å¤‡æ•°æ®..."
                
                print(f"å¤„ç†ç¬¬ {batch_num + 1}/{total_batches} æ‰¹ï¼Œåç§»é‡: {offset}")
                
                try:
                    # æ„å»ºæ‰¹æ¬¡æŸ¥è¯¢ï¼Œç¡®ä¿ä¸è¶…è¿‡æ€»é™åˆ¶
                    remaining = total_count - offset
                    actual_limit = min(batch_size, remaining)
                    if actual_limit <= 0:
                        break
                        
                    # åªæŸ¥è¯¢ç‰¹å¾æå–å™¨éœ€è¦çš„å­—æ®µï¼ˆæ’é™¤iTypeå’ŒcDescï¼‰
                    required_fields = [
                        Equipment.equip_level, Equipment.kindid, Equipment.init_damage, Equipment.init_damage_raw,
                        Equipment.all_damage, Equipment.init_wakan, Equipment.init_defense, Equipment.init_hp,
                        Equipment.init_dex, Equipment.mingzhong, Equipment.shanghai, Equipment.addon_tizhi,
                        Equipment.addon_liliang, Equipment.addon_naili, Equipment.addon_minjie, Equipment.addon_lingli,
                        Equipment.addon_moli, Equipment.agg_added_attrs, Equipment.gem_value, Equipment.gem_level,
                        Equipment.special_skill, Equipment.special_effect, Equipment.suit_effect, Equipment.large_equip_desc,
                        Equipment.equip_sn, Equipment.price, Equipment.server_name, Equipment.update_time
                    ]
                    query = db.session.query(*required_fields).offset(offset).limit(actual_limit)
                    equipments = query.all()
                    
                    if not equipments:
                        print(f"ç¬¬ {batch_num + 1} æ‰¹æ— æ•°æ®ï¼Œè·³è¿‡")
                        continue
                    
                    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ - ç°åœ¨æŸ¥è¯¢è¿”å›çš„æ˜¯å…ƒç»„
                    batch_data = []
                    field_names = [
                        'equip_level', 'kindid', 'init_damage', 'init_damage_raw', 'all_damage',
                        'init_wakan', 'init_defense', 'init_hp', 'init_dex', 'mingzhong', 'shanghai',
                        'addon_tizhi', 'addon_liliang', 'addon_naili', 'addon_minjie', 'addon_lingli', 'addon_moli',
                        'agg_added_attrs', 'gem_value', 'gem_level', 'special_skill', 'special_effect', 'suit_effect',
                        'large_equip_desc', 'equip_sn', 'price', 'server_name', 'update_time'
                    ]
                    
                    for equipment_tuple in equipments:
                        equipment_dict = {}
                        for i, value in enumerate(equipment_tuple):
                            field_name = field_names[i]
                            if hasattr(value, 'isoformat'):  # datetimeå¯¹è±¡
                                equipment_dict[field_name] = value.isoformat()
                            else:
                                equipment_dict[field_name] = value
                        batch_data.append(equipment_dict)
                    
                    all_data.extend(batch_data)
                    self._refresh_processed_records += len(batch_data)
                    
                    progress_percentage = (self._refresh_processed_records / total_count) * 100
                    print(f"å·²å¤„ç† {self._refresh_processed_records}/{total_count} æ¡æ•°æ® ({progress_percentage:.1f}%)")
                    
                    offset += batch_size
                    
                    # æ¯å¤„ç†å‡ æ‰¹å°±å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œé‡Šæ”¾å†…å­˜
                    if batch_num % 5 == 0:
                        import gc
                        gc.collect()
                        
                except Exception as e:
                    self.logger.error(f"å¤„ç†ç¬¬ {batch_num + 1} æ‰¹æ•°æ®å¤±è´¥: {e}")
                    continue
            
            if not all_data:
                print("æœªæ‰¾åˆ°è£…å¤‡æ•°æ®")
                self._refresh_status = "error"
                self._refresh_message = "æœªæ‰¾åˆ°è£…å¤‡æ•°æ®"
                return False
            
            # è½¬æ¢ä¸ºDataFrame
            self._refresh_message = "æ„å»ºæ•°æ®ç»“æ„..."
            self._refresh_progress = 92
            
            df = pd.DataFrame(all_data)
            print(f"æ€»å…±åŠ è½½ {len(df)} æ¡è£…å¤‡æ•°æ®")
            
            # å­˜å‚¨åˆ°Redisåˆ†å—ç¼“å­˜
            self._refresh_message = "ä¿å­˜åˆ°Redisç¼“å­˜..."
            self._refresh_progress = 95
            
            chunk_size = 500  # å‡å°å—å¤§å°ï¼Œé¿å…è¶…æ—¶
            ttl_seconds = None if self._cache_ttl_hours == -1 else self._cache_ttl_hours * 3600
            
            print(f"å‡†å¤‡å­˜å‚¨åˆ°Redisï¼Œæ•°æ®é‡: {len(df)} æ¡ï¼Œå—å¤§å°: {chunk_size}")
            
            # é‡è¯•æœºåˆ¶
            success = False
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    print(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å­˜å‚¨åˆ°Redis...")
                    success = self.redis_cache.set_chunked_data(
                        base_key=self._full_cache_key,
                        data=df,
                        chunk_size=chunk_size,
                        ttl=ttl_seconds
                    )
                    if success:
                        print("Rediså­˜å‚¨æˆåŠŸï¼")
                        break
                    else:
                        print(f"ç¬¬ {attempt + 1} æ¬¡å­˜å‚¨å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
                except Exception as e:
                    print(f"ç¬¬ {attempt + 1} æ¬¡å­˜å‚¨å¼‚å¸¸: {e}")
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    else:
                        print("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
            
            if success:
                elapsed_time = time.time() - start_time
                cache_info = "æ°¸ä¸è¿‡æœŸï¼ˆä»…æ‰‹åŠ¨åˆ·æ–°ï¼‰" if self._cache_ttl_hours == -1 else f"{self._cache_ttl_hours}å°æ—¶"
                print(f"å…¨é‡è£…å¤‡æ•°æ®å·²ç¼“å­˜åˆ°Redisï¼Œç¼“å­˜ç­–ç•¥: {cache_info}ï¼Œæ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
                self._full_data_cache = df  # åŒæ—¶ç¼“å­˜åˆ°å†…å­˜
                
                # å®Œæˆè¿›åº¦è·Ÿè¸ª
                self._refresh_status = "completed"
                self._refresh_progress = 100
                self._refresh_message = "è£…å¤‡æ•°æ®åŠ è½½å®Œæˆï¼"
                
                return True
            else:
                print("Redisç¼“å­˜å¤±è´¥")
                self._refresh_status = "error"
                self._refresh_message = "Redisç¼“å­˜å¤±è´¥"
                return False
                
        except Exception as e:
            self.logger.error(f"åŠ è½½å…¨é‡æ•°æ®åˆ°Rediså¤±è´¥: {e}")
            print(f"åŠ è½½å…¨é‡æ•°æ®å¤±è´¥: {e}")
            self._refresh_status = "error"
            self._refresh_message = f"åŠ è½½å¤±è´¥: {str(e)}"
            return False

    def _get_full_data_from_redis(self) -> Optional[pd.DataFrame]:
        """ä»Redisè·å–å…¨é‡è£…å¤‡æ•°æ®"""
        if not self.redis_cache:
            return None
            
        try:
            # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
            if self._full_data_cache is not None and not self._full_data_cache.empty:
                print(f"ä»å†…å­˜ç¼“å­˜è·å–å…¨é‡æ•°æ®: {len(self._full_data_cache)} æ¡")
                return self._full_data_cache
            
            # ä»Redisè·å–åˆ†å—æ•°æ®
            cached_data = self.redis_cache.get_chunked_data(self._full_cache_key)
            
            if cached_data is not None and not cached_data.empty:
                print(f"ä»Redisåˆ†å—ç¼“å­˜è·å–å…¨é‡æ•°æ®: {len(cached_data)} æ¡")
                self._full_data_cache = cached_data  # ç¼“å­˜åˆ°å†…å­˜
                return cached_data
            else:
                print("Rediså…¨é‡ç¼“å­˜æœªå‘½ä¸­")
                return None
                
        except Exception as e:
            self.logger.warning(f"ä»Redisè·å–å…¨é‡æ•°æ®å¤±è´¥: {e}")
            return None

    def _filter_data_from_full_cache(self, full_data: pd.DataFrame, **filters) -> pd.DataFrame:
        """
        ä»Rediså…¨é‡æ•°æ®ä¸­è¿›è¡Œç­›é€‰ - ä½¿ç”¨pandasé«˜æ•ˆç­›é€‰
        
        Args:
            full_data: å…¨é‡è£…å¤‡æ•°æ®
            **filters: ç­›é€‰æ¡ä»¶
            
        Returns:
            ç­›é€‰åçš„DataFrame
        """
        try:
            filtered_df = full_data.copy()
            
            # åŸºç¡€ç­›é€‰æ¡ä»¶
            kindid = filters.get('kindid')
            level_range = filters.get('level_range')
            price_range = filters.get('price_range')
            server = filters.get('server')
            special_skill = filters.get('special_skill')
            suit_effect = filters.get('suit_effect')
            special_effect = filters.get('special_effect')
            exclude_special_effect = filters.get('exclude_special_effect')
            exclude_suit_effect = filters.get('exclude_suit_effect')
            exclude_high_value_simple_equips = filters.get('exclude_high_value_simple_equips', False)
            require_high_value_suits = filters.get('require_high_value_suits', False)
            exclude_high_value_special_skills = filters.get('exclude_high_value_special_skills', False)
            limit = filters.get('limit', 1000)
            
            print(f"å¼€å§‹ä» {len(filtered_df)} æ¡å…¨é‡æ•°æ®ä¸­ç­›é€‰...")
            
            # 1. è£…å¤‡ç±»å‹ç­›é€‰
            if kindid is not None:
                filtered_df = filtered_df[filtered_df['kindid'] == kindid]
                print(f"æŒ‰è£…å¤‡ç±»å‹({kindid})ç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 2. ç­‰çº§èŒƒå›´ç­›é€‰
            if level_range:
                min_level, max_level = level_range
                filtered_df = filtered_df[
                    (filtered_df['equip_level'] >= min_level) & 
                    (filtered_df['equip_level'] <= max_level)
                ]
                print(f"æŒ‰ç­‰çº§èŒƒå›´({min_level}-{max_level})ç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 3. ä»·æ ¼èŒƒå›´ç­›é€‰
            if price_range:
                min_price, max_price = price_range
                filtered_df = filtered_df[
                    (filtered_df['price'] >= min_price) & 
                    (filtered_df['price'] <= max_price)
                ]
                print(f"æŒ‰ä»·æ ¼èŒƒå›´({min_price}-{max_price})ç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 4. æœåŠ¡å™¨ç­›é€‰
            if server:
                filtered_df = filtered_df[filtered_df['server_name'] == server]
                print(f"æŒ‰æœåŠ¡å™¨({server})ç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 5. ç‰¹æŠ€ç­›é€‰
            if special_skill is not None:
                if not exclude_high_value_special_skills:
                    filtered_df = filtered_df[filtered_df['special_skill'] == special_skill]
                    print(f"æŒ‰ç‰¹æŠ€({special_skill})ç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 6. æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€è£…å¤‡
            if exclude_high_value_special_skills:
                low_value_condition = (
                    (filtered_df['special_skill'] == 0) |
                    (filtered_df['special_skill'].isna()) |
                    (filtered_df['special_skill'].isin(LOW_VALUE_SPECIAL_SKILLS))
                )
                filtered_df = filtered_df[low_value_condition]
                print(f"æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€å: {len(filtered_df)} æ¡")
            
            # 7. å¥—è£…æ•ˆæœç­›é€‰
            if suit_effect is not None:
                try:
                    suit_effect_num = int(suit_effect) if suit_effect is not None else 0
                    if suit_effect_num > 0:
                        filtered_df = filtered_df[filtered_df['suit_effect'] == suit_effect_num]
                        print(f"æŒ‰å¥—è£…æ•ˆæœ({suit_effect_num})ç­›é€‰å: {len(filtered_df)} æ¡")
                except (ValueError, TypeError):
                    if suit_effect and str(suit_effect).strip():
                        filtered_df = filtered_df[filtered_df['suit_effect'] == suit_effect]
                        print(f"æŒ‰å¥—è£…æ•ˆæœ({suit_effect})ç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 8. å¼ºåˆ¶åŒ…å«é«˜ä»·å€¼å¥—è£…
            if require_high_value_suits:
                high_value_suits = HIGH_VALUE_SUITS
                if high_value_suits:
                    filtered_df = filtered_df[filtered_df['suit_effect'].isin(high_value_suits)]
                    print(f"å¼ºåˆ¶åŒ…å«é«˜ä»·å€¼å¥—è£…å: {len(filtered_df)} æ¡")
            
            # 9. ç‰¹æ•ˆç­›é€‰ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
            if special_effect and len(special_effect) > 0:
                effect_mask = pd.Series([False] * len(filtered_df))
                for effect in special_effect:
                    if effect not in LOW_VALUE_EFFECTS:
                        # ä½¿ç”¨å­—ç¬¦ä¸²åŒ…å«æ£€æŸ¥ï¼ˆç¦ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
                        effect_condition = (
                            filtered_df['special_effect'].str.contains(f'[{effect}]', na=False, regex=False) |
                            filtered_df['special_effect'].str.contains(f'[{effect},', na=False, regex=False) |
                            filtered_df['special_effect'].str.contains(f',{effect},', na=False, regex=False) |
                            filtered_df['special_effect'].str.contains(f',{effect}]', na=False, regex=False)
                        )
                        effect_mask = effect_mask | effect_condition
                
                filtered_df = filtered_df[effect_mask]
                print(f"æŒ‰ç‰¹æ•ˆç­›é€‰å: {len(filtered_df)} æ¡")
            
            # 10. æ’é™¤ç‰¹æ•ˆç­›é€‰
            if exclude_special_effect and len(exclude_special_effect) > 0:
                exclude_mask = pd.Series([True] * len(filtered_df))
                for effect in exclude_special_effect:
                    effect_condition = (
                        filtered_df['special_effect'].str.contains(f'[{effect}]', na=False, regex=False) |
                        filtered_df['special_effect'].str.contains(f'[{effect},', na=False, regex=False) |
                        filtered_df['special_effect'].str.contains(f',{effect},', na=False, regex=False) |
                        filtered_df['special_effect'].str.contains(f',{effect}]', na=False, regex=False)
                    )
                    exclude_mask = exclude_mask & ~effect_condition
                
                filtered_df = filtered_df[exclude_mask]
                print(f"æ’é™¤ç‰¹æ•ˆå: {len(filtered_df)} æ¡")
            
            # 11. æ’é™¤å¥—è£…æ•ˆæœ
            if exclude_suit_effect and len(exclude_suit_effect) > 0:
                filtered_df = filtered_df[~filtered_df['suit_effect'].isin(exclude_suit_effect)]
                print(f"æ’é™¤å¥—è£…æ•ˆæœå: {len(filtered_df)} æ¡")
            
            # 12. æ’é™¤é«˜ä»·å€¼ç®€æ˜“è£…å¤‡
            if exclude_high_value_simple_equips:
                high_value_levels = HIGH_VALUE_EQUIP_LEVELS
                simple_effect_id = SIMPLE_EFFECT_ID
                
                # æ’é™¤æŒ‡å®šç­‰çº§ä¸”æœ‰ç®€æ˜“ç‰¹æ•ˆçš„è£…å¤‡
                exclude_condition = pd.Series([False] * len(filtered_df))
                for level in high_value_levels:
                    level_condition = (filtered_df['equip_level'] == level)
                    simple_condition = (
                        filtered_df['special_effect'].str.contains(f'[{simple_effect_id}]', na=False, regex=False) |
                        filtered_df['special_effect'].str.contains(f'[{simple_effect_id},', na=False, regex=False) |
                        filtered_df['special_effect'].str.contains(f',{simple_effect_id},', na=False, regex=False) |
                        filtered_df['special_effect'].str.contains(f',{simple_effect_id}]', na=False, regex=False)
                    )
                    exclude_condition = exclude_condition | (level_condition & simple_condition)
                
                filtered_df = filtered_df[~exclude_condition]
                print(f"æ’é™¤é«˜ä»·å€¼ç®€æ˜“è£…å¤‡å: {len(filtered_df)} æ¡")
            
            # 13. æŒ‰æ›´æ–°æ—¶é—´æ’åºå¹¶é™åˆ¶æ•°é‡
            if 'update_time' in filtered_df.columns:
                # ç¡®ä¿update_timeæ˜¯datetimeç±»å‹
                if filtered_df['update_time'].dtype == 'object':
                    filtered_df['update_time'] = pd.to_datetime(filtered_df['update_time'])
                
                filtered_df = filtered_df.sort_values('update_time', ascending=False)
            
            # 14. é™åˆ¶è¿”å›æ•°é‡
            if len(filtered_df) > limit:
                filtered_df = filtered_df.head(limit)
                print(f"é™åˆ¶è¿”å›æ•°é‡åˆ°: {limit} æ¡")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"ä»Rediså…¨é‡æ•°æ®ç­›é€‰å¤±è´¥: {e}")
            print(f"Redisç­›é€‰å¼‚å¸¸: {e}")
            return pd.DataFrame()

    def get_market_data(self,
                        kindid: Optional[int] = None,
                        level_range: Optional[Tuple[int, int]] = None,
                        price_range: Optional[Tuple[float, float]] = None,
                        server: Optional[str] = None,
                        special_skill: Optional[int] = None,
                        suit_effect: Optional[int] = None,
                        special_effect: Optional[List[str]] = None,
                        exclude_special_effect: Optional[List[int]] = None,
                        exclude_suit_effect: Optional[List[int]] = None,
                        exclude_high_value_simple_equips: bool = False,
                        require_high_value_suits: bool = False,
                        exclude_high_value_special_skills: bool = False,
                        limit: int = 1000,
                        use_redis_cache: bool = True) -> pd.DataFrame:
        """
        è·å–å¸‚åœºè£…å¤‡æ•°æ® - ä¼˜å…ˆä»Rediså…¨é‡ç¼“å­˜è·å–å¹¶ç­›é€‰

        Args:
            kindid: è£…å¤‡ç±»å‹IDç­›é€‰
            level_range: ç­‰çº§èŒƒå›´ (min_level, max_level)
            price_range: ä»·æ ¼èŒƒå›´ (min_price, max_price)
            server: æœåŠ¡å™¨ç­›é€‰
            special_effect: ç‰¹æ•ˆç­›é€‰ï¼ˆé«˜ä»·å€¼å¿…é¡»åŒ…å«ï¼‰
            require_high_value_suits: å¼ºåˆ¶åŒ…å«é«˜ä»·å€¼å¥—è£…è£…å¤‡ï¼ˆé­”åŠ›å¥—å’Œæ•æ·å¥—ï¼‰
            special_skill: ç‰¹æŠ€ç­›é€‰ï¼ˆå¿…é¡»å®Œå…¨ä¸€è‡´ï¼‰
            exclude_special_effect: æ’é™¤ç‰¹æ•ˆç­›é€‰ï¼ˆæ’é™¤å…·æœ‰è¿™äº›ç‰¹æ•ˆçš„è£…å¤‡ï¼‰
            exclude_suit_effect: æ’é™¤å¥—è£…æ•ˆæœç­›é€‰ï¼ˆæ’é™¤å…·æœ‰è¿™äº›å¥—è£…æ•ˆæœçš„è£…å¤‡ï¼‰
            exclude_high_value_simple_equips: æ’é™¤é«˜ä»·å€¼ç®€æ˜“è£…å¤‡ï¼ˆ70/90/110/130çº§çš„ç®€æ˜“è£…å¤‡ï¼‰
            exclude_high_value_special_skills: æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€è£…å¤‡ï¼ˆåªæœç´¢æ— ç‰¹æŠ€æˆ–ä½ä»·å€¼ç‰¹æŠ€è£…å¤‡ï¼‰
            suit_effect: å¥—è£…æ•ˆæœæœ‰ä¸‰ç§ï¼Œå¦‚æœæ˜¯"é™„åŠ çŠ¶æ€"/"è¿½åŠ æ³•æœ¯"ï¼Œåˆ™ä¼ å…¥è¿‡æ»¤ï¼Œ"å˜èº«æœ¯"/"å˜åŒ–å’’"ï¼Œåˆ™ä¸ä¼ å…¥è¿‡æ»¤ï¼Œåœ¨é”šå®šçš„æ—¶å€™åšèšç±»
            limit: è¿”å›æ•°æ®æ¡æ•°é™åˆ¶
            use_redis_cache: æ˜¯å¦ä½¿ç”¨Redisç¼“å­˜

        Returns:
            è£…å¤‡å¸‚åœºæ•°æ®DataFrame
            
        """
        try:
            import time
            start_time = time.time()
            
            # ä¼˜å…ˆä»Rediså…¨é‡ç¼“å­˜è·å–æ•°æ®
            if use_redis_cache and self.redis_cache:
                full_data = self._get_full_data_from_redis()
                
                if full_data is None or full_data.empty:
                    # ç¼“å­˜æœªå‘½ä¸­ï¼Œå°è¯•åŠ è½½å…¨é‡æ•°æ®åˆ°Redis
                    print("Redisç¼“å­˜æœªå‘½ä¸­ï¼Œå¼€å§‹åŠ è½½å…¨é‡æ•°æ®...")
                    if self._load_full_data_to_redis():
                        full_data = self._get_full_data_from_redis()
                
                if full_data is not None and not full_data.empty:
                    # ä»Rediså…¨é‡æ•°æ®ä¸­è¿›è¡Œç­›é€‰
                    filtered_data = self._filter_data_from_full_cache(
                        full_data=full_data,
                        kindid=kindid,
                        level_range=level_range,
                        price_range=price_range,
                        server=server,
                        special_skill=special_skill,
                        suit_effect=suit_effect,
                        special_effect=special_effect,
                        exclude_special_effect=exclude_special_effect,
                        exclude_suit_effect=exclude_suit_effect,
                        exclude_high_value_simple_equips=exclude_high_value_simple_equips,
                        require_high_value_suits=require_high_value_suits,
                        exclude_high_value_special_skills=exclude_high_value_special_skills,
                        limit=limit
                    )
                    
                    elapsed_time = time.time() - start_time
                    print(f"ä»Rediså…¨é‡ç¼“å­˜ç­›é€‰å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.3f}ç§’ï¼Œè¿”å›: {len(filtered_data)} æ¡æ•°æ®")
                    return filtered_data
            
            # é™çº§åˆ°MySQLæŸ¥è¯¢
            print("ä½¿ç”¨MySQLæ•°æ®åº“æŸ¥è¯¢ï¼ˆé™çº§æ¨¡å¼ï¼‰...")
            return self._get_market_data_from_mysql(
                kindid=kindid,
                level_range=level_range,
                price_range=price_range,
                server=server,
                special_skill=special_skill,
                suit_effect=suit_effect,
                special_effect=special_effect,
                exclude_special_effect=exclude_special_effect,
                exclude_suit_effect=exclude_suit_effect,
                exclude_high_value_simple_equips=exclude_high_value_simple_equips,
                require_high_value_suits=require_high_value_suits,
                exclude_high_value_special_skills=exclude_high_value_special_skills,
                limit=limit
            )

        except Exception as e:
            self.logger.error(f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            print(f"æŸ¥è¯¢å¼‚å¸¸: {e}")
            return pd.DataFrame()

    def _get_market_data_from_mysql(self,
                                   kindid: Optional[int] = None,
                                   level_range: Optional[Tuple[int, int]] = None,
                                   price_range: Optional[Tuple[float, float]] = None,
                                   server: Optional[str] = None,
                                   special_skill: Optional[int] = None,
                                   suit_effect: Optional[int] = None,
                                   special_effect: Optional[List[str]] = None,
                                   exclude_special_effect: Optional[List[int]] = None,
                                   exclude_suit_effect: Optional[List[int]] = None,
                                   exclude_high_value_simple_equips: bool = False,
                                   require_high_value_suits: bool = False,
                                   exclude_high_value_special_skills: bool = False,
                                   limit: int = 1000) -> pd.DataFrame:
        """
        ä»MySQLæ•°æ®åº“è·å–è£…å¤‡æ•°æ®ï¼ˆåŸå§‹æŸ¥è¯¢é€»è¾‘ï¼‰
        """
        try:
            # æ„å»ºSQLAlchemyæŸ¥è¯¢ - åªæŸ¥è¯¢ç‰¹å¾æå–å™¨éœ€è¦çš„å­—æ®µ
            # æ ¹æ®ç‰¹å¾æå–å™¨ç»Ÿè®¡ï¼Œéœ€è¦ä»¥ä¸‹å­—æ®µï¼ˆæ’é™¤iTypeå’ŒcDescï¼‰ï¼š
            required_fields = [
                Equipment.equip_level,
                Equipment.kindid,
                Equipment.init_damage,
                Equipment.init_damage_raw,
                Equipment.all_damage,
                Equipment.init_wakan,
                Equipment.init_defense,
                Equipment.init_hp,
                Equipment.init_dex,
                Equipment.mingzhong,
                Equipment.shanghai,
                Equipment.addon_tizhi,
                Equipment.addon_liliang,
                Equipment.addon_naili,
                Equipment.addon_minjie,
                Equipment.addon_lingli,
                Equipment.addon_moli,
                Equipment.agg_added_attrs,
                Equipment.gem_value,
                Equipment.gem_level,
                Equipment.special_skill,
                Equipment.special_effect,
                Equipment.suit_effect,
                Equipment.large_equip_desc,
                # ä¿ç•™ä¸€äº›å¿…è¦çš„å…ƒæ•°æ®å­—æ®µ
                Equipment.equip_sn,
                Equipment.price,
                Equipment.server_name,
                Equipment.update_time
            ]
            query = db.session.query(*required_fields)

            if kindid is not None:
                query = query.filter(Equipment.kindid == kindid)

            if special_skill is not None:
                # åªæœ‰å½“ä¸éœ€è¦æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€æ—¶ï¼Œæ‰æ·»åŠ å…·ä½“çš„ç‰¹æŠ€ç­›é€‰æ¡ä»¶
                if not (exclude_high_value_special_skills or not require_high_value_suits):
                    query = query.filter(Equipment.special_skill == special_skill)
                else:
                    print(f"è·³è¿‡å…·ä½“ç‰¹æŠ€ç­›é€‰ï¼Œå› ä¸ºéœ€è¦æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€")

            # ç‰¹æŠ€ç­›é€‰é€»è¾‘ï¼šå¦‚æœç›®æ ‡è£…å¤‡æ˜¯ä½ä»·å€¼ç‰¹æŠ€ï¼Œåˆ™æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€è£…å¤‡
            if exclude_high_value_special_skills:
                # åªèƒ½æœç´¢æ— ç‰¹æŠ€æˆ–ä½ä»·å€¼ç‰¹æŠ€çš„è£…å¤‡
                query = query.filter(
                    or_(
                        Equipment.special_skill == 0,
                        Equipment.special_skill.is_(None),
                        Equipment.special_skill.in_(LOW_VALUE_SPECIAL_SKILLS)
                    )
                )
                print(f"ç‰¹æŠ€ç­›é€‰ï¼šåªæœç´¢æ— ç‰¹æŠ€æˆ–ä½ä»·å€¼ç‰¹æŠ€è£…å¤‡")

            if suit_effect is not None:
                # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å­—åå†æ¯”è¾ƒï¼ˆpet_equipé™¤å¤–ï¼Œå…¶ä»–éƒ½æ˜¯æ•°å­—å­—ç¬¦ä¸²ï¼‰
                try:
                    suit_effect_num = int(suit_effect) if suit_effect is not None else 0
                    if suit_effect_num > 0:
                        query = query.filter(Equipment.suit_effect == suit_effect_num)
                except (ValueError, TypeError):
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼ˆå¯èƒ½æ˜¯pet_equipçš„å­—ç¬¦ä¸²å¥—è£…ï¼‰ï¼Œç›´æ¥ä½¿ç”¨åŸå€¼
                    if suit_effect and str(suit_effect).strip():
                        query = query.filter(Equipment.suit_effect == suit_effect)

            if require_high_value_suits:
                # å¼ºåˆ¶åŒ…å«é«˜ä»·å€¼å¥—è£…ï¼šåªæœç´¢é­”åŠ›å¥—å’Œæ•æ·å¥—è£…å¤‡
                high_value_suits = HIGH_VALUE_SUITS
                if high_value_suits:
                    query = query.filter(Equipment.suit_effect.in_(high_value_suits))
                    print(f"å¼ºåˆ¶åŒ…å«é«˜ä»·å€¼å¥—è£…ï¼šåªæœç´¢é­”åŠ›å¥—å’Œæ•æ·å¥—è£…å¤‡")

            if special_effect is not None:
                # ç‰¹æ•ˆç­›é€‰ï¼ˆå¤šé€‰ï¼ŒJSONæ•°ç»„æ ¼å¼ï¼‰
                if special_effect and len(special_effect) > 0:
                    effect_conditions = []
                    for effect in special_effect:
                        if effect not in LOW_VALUE_EFFECTS:  # æ’é™¤ä½ä»·å€¼ç‰¹æ•ˆ
                            effect_conditions.append(
                                or_(
                                    Equipment.special_effect.like(f'[{effect}]'),
                                    Equipment.special_effect.like(f'[{effect},%'),
                                    Equipment.special_effect.like(f'%,{effect},%'),
                                    Equipment.special_effect.like(f'%,{effect}]')
                                )
                            )
                    
                    if effect_conditions:
                        query = query.filter(or_(*effect_conditions))

            if exclude_special_effect is not None:
                # æ’é™¤ç‰¹æ•ˆç­›é€‰ï¼šæ’é™¤å…·æœ‰æŒ‡å®šç‰¹æ•ˆçš„è£…å¤‡
                if exclude_special_effect and len(exclude_special_effect) > 0:
                    exclude_conditions = []
                    for effect in exclude_special_effect:
                        exclude_conditions.append(
                            ~or_(
                                Equipment.special_effect.like(f'[{effect}]'),
                                Equipment.special_effect.like(f'[{effect},%'),
                                Equipment.special_effect.like(f'%,{effect},%'),
                                Equipment.special_effect.like(f'%,{effect}]')
                            )
                        )
                    
                    if exclude_conditions:
                        query = query.filter(and_(*exclude_conditions))

            if exclude_suit_effect is not None:
                # æ’é™¤å¥—è£…æ•ˆæœç­›é€‰ï¼šæ’é™¤å…·æœ‰æŒ‡å®šå¥—è£…æ•ˆæœçš„è£…å¤‡
                if exclude_suit_effect and len(exclude_suit_effect) > 0:
                    query = query.filter(~Equipment.suit_effect.in_(exclude_suit_effect))

            if exclude_high_value_simple_equips:
                # æ’é™¤é«˜ä»·å€¼ç®€æ˜“è£…å¤‡ï¼šæ’é™¤70çº§/90çº§/110çº§/130çº§ä¸”æœ‰ç®€æ˜“ç‰¹æ•ˆ(2)çš„è£…å¤‡
                high_value_levels = HIGH_VALUE_EQUIP_LEVELS
                simple_effect_conditions = []
                
                for level in high_value_levels:
                    # å¯¹äºæ¯ä¸ªé«˜ä»·å€¼ç­‰çº§ï¼Œæ’é™¤è¯¥ç­‰çº§ä¸”æœ‰ç®€æ˜“ç‰¹æ•ˆçš„è£…å¤‡
                    simple_conditions = or_(
                        Equipment.special_effect.like(f'[{SIMPLE_EFFECT_ID}]'),
                        Equipment.special_effect.like(f'[{SIMPLE_EFFECT_ID},%'),
                        Equipment.special_effect.like(f'%,{SIMPLE_EFFECT_ID},%'),
                        Equipment.special_effect.like(f'%,{SIMPLE_EFFECT_ID}]')
                    )
                    simple_effect_conditions.append(
                        ~(Equipment.equip_level == level) | ~simple_conditions
                    )
                
                if simple_effect_conditions:
                    query = query.filter(and_(*simple_effect_conditions))
                    print(f"æ’é™¤é«˜ä»·å€¼ç®€æ˜“è£…å¤‡ï¼š70çº§/90çº§/110çº§/130çº§ä¸”æœ‰ç®€æ˜“ç‰¹æ•ˆçš„è£…å¤‡")

            if level_range:
                query = query.filter(Equipment.equip_level.between(level_range[0], level_range[1]))

            if price_range:
                query = query.filter(Equipment.price.between(price_range[0], price_range[1]))

            if server:
                query = query.filter(Equipment.server_name == server)

            # æ’åºå’Œé™åˆ¶
            query = query.order_by(Equipment.update_time.desc()).limit(limit)

            # æ‰§è¡ŒæŸ¥è¯¢å¹¶è½¬æ¢ä¸ºDataFrame
            equipments = query.all()
            
            if equipments:
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ - ç°åœ¨æŸ¥è¯¢è¿”å›çš„æ˜¯å…ƒç»„
                data_list = []
                field_names = [
                    'equip_level', 'kindid', 'init_damage', 'init_damage_raw', 'all_damage',
                    'init_wakan', 'init_defense', 'init_hp', 'init_dex', 'mingzhong', 'shanghai',
                    'addon_tizhi', 'addon_liliang', 'addon_naili', 'addon_minjie', 'addon_lingli', 'addon_moli',
                    'agg_added_attrs', 'gem_value', 'gem_level', 'special_skill', 'special_effect', 'suit_effect',
                    'large_equip_desc', 'equip_sn', 'price', 'server_name', 'update_time'
                ]
                
                for equipment_tuple in equipments:
                    equipment_dict = {}
                    for i, value in enumerate(equipment_tuple):
                        field_name = field_names[i]
                        if hasattr(value, 'isoformat'):  # datetimeå¯¹è±¡
                            equipment_dict[field_name] = value.isoformat()
                        else:
                            equipment_dict[field_name] = value
                    data_list.append(equipment_dict)
                
                df = pd.DataFrame(data_list)
                print(f"ä»MySQLæ•°æ®åº“åŠ è½½äº† {len(df)} æ¡è£…å¤‡æ•°æ®")
                return df
            else:
                print(f"ä»MySQLæ•°æ®åº“æŸ¥è¯¢åˆ°0æ¡æ•°æ®")
                return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢è£…å¤‡æ•°æ®å¤±è´¥: {e}")
            print(f"SQLæ‰§è¡Œå¼‚å¸¸: {e}")
            return pd.DataFrame()

    def get_market_data_for_similarity(self,
                                       target_features: Dict[str, Any]) -> pd.DataFrame:
        """
        è·å–ç”¨äºç›¸ä¼¼åº¦è®¡ç®—çš„å¸‚åœºæ•°æ®

        ä¸“é—¨ä¸ºç›¸ä¼¼åº¦è®¡ç®—ä¼˜åŒ–çš„æ•°æ®è·å–æ–¹æ³•ï¼ŒåŒ…å«ä»¥ä¸‹ç‰¹æ®Šé€»è¾‘ï¼š
        1. é«˜ä»·å€¼ç‰¹æ•ˆçš„å…¬å¹³æ€§ç­›é€‰
        2. é«˜ä»·å€¼å¥—è£…çš„å…¬å¹³æ€§ç­›é€‰
        3. ç›¸ä¼¼åº¦è®¡ç®—ç›¸å…³çš„ç‰¹æ•ˆç­›é€‰
        4. é€‚å½“çš„æ•°æ®é‡æ§åˆ¶

        Args:
            target_features: ç›®æ ‡è£…å¤‡ç‰¹å¾

        Returns:
            å¸‚åœºæ•°æ®DataFrame
        """
        try:
            # æå–åŸºç¡€ç­›é€‰æ¡ä»¶
            level_range = target_features.get('equip_level_range', None)
            kindid = target_features.get('kindid', None)
            special_skill = target_features.get('special_skill', 0)
            special_effect = target_features.get('special_effect', [])
            suit_effect = target_features.get('suit_effect', 0)

            # å¤„ç†ç‰¹æ•ˆç­›é€‰é€»è¾‘
            filtered_special_effect = None
            exclude_special_effect = None
            exclude_high_value_simple_equips = False

            # ä½¿ç”¨é¢„å®šä¹‰çš„ç‰¹æ•ˆå’Œç­‰çº§å¸¸é‡
            high_value_effects = HIGH_VALUE_EFFECTS
            important_effects = IMPORTANT_EFFECTS

            # ç®€æ˜“è£…å¤‡ç‰¹æ®Šé€»è¾‘å¤„ç†
            target_equip_level = target_features.get('equip_level', 0)
            simple_effect_id = SIMPLE_EFFECT_ID
            high_value_equip_levels = HIGH_VALUE_EQUIP_LEVELS

            # æ£€æŸ¥ç›®æ ‡è£…å¤‡æ˜¯å¦åŒ…å«é«˜ä»·å€¼ç‰¹æ•ˆ
            target_has_high_value_effects = False
            target_has_simple_effect = False
            
            if special_effect and len(special_effect) > 0:
                # ç­›é€‰å‡ºé‡è¦ç‰¹æ•ˆç”¨äºç›¸ä¼¼åº¦è®¡ç®—
                filtered_effects = []
                for effect in special_effect:
                    if effect in important_effects:
                        # å¦‚æœç‰¹æ•ˆæ˜¯ SIMPLE_EFFECT_IDï¼Œåˆ™ç­‰çº§è¦ç¬¦åˆ HIGH_VALUE_EQUIP_LEVELS
                        if effect != simple_effect_id or (effect == simple_effect_id and target_equip_level in high_value_equip_levels):
                            filtered_effects.append(effect)
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºç¡€é«˜ä»·å€¼ç‰¹æ•ˆï¼ˆæ— çº§åˆ«ã€æ„¤æ€’ã€æ°¸ä¸ç£¨æŸï¼‰
                    if effect in high_value_effects:
                        target_has_high_value_effects = True
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç®€æ˜“ç‰¹æ•ˆ
                    if effect == simple_effect_id:
                        target_has_simple_effect = True

                if filtered_effects:
                    filtered_special_effect = filtered_effects

            # åˆ¤æ–­ç›®æ ‡è£…å¤‡æ˜¯å¦æœ‰é«˜ä»·å€¼ç®€æ˜“ç‰¹æ•ˆ
            if target_has_simple_effect and target_equip_level in high_value_equip_levels:
                target_has_high_value_effects = True
                print(f"ç›®æ ‡è£…å¤‡{target_equip_level}çº§ç®€æ˜“è£…å¤‡è§†ä¸ºé«˜ä»·å€¼ç‰¹æ•ˆ")

            # å…¬å¹³æ€§ç­›é€‰ï¼šå¦‚æœç›®æ ‡è£…å¤‡ä¸åŒ…å«é«˜ä»·å€¼ç‰¹æ•ˆï¼Œåˆ™æ’é™¤å…·æœ‰è¿™äº›ç‰¹æ•ˆçš„è£…å¤‡
            if not target_has_high_value_effects:
                # æ’é™¤åŸºç¡€é«˜ä»·å€¼ç‰¹æ•ˆ
                exclude_special_effect = high_value_effects
                # æ’é™¤é«˜ä»·å€¼ç®€æ˜“è£…å¤‡ï¼ˆ70/90/130çº§çš„ç®€æ˜“è£…å¤‡ï¼‰
                exclude_high_value_simple_equips = True
                print(
                    f"ç›®æ ‡è£…å¤‡ä¸åŒ…å«é«˜ä»·å€¼ç‰¹æ•ˆï¼Œå°†æ’é™¤åŸºç¡€é«˜ä»·å€¼ç‰¹æ•ˆ {high_value_effects} å’Œ70çº§/90çº§/130çº§ç®€æ˜“è£…å¤‡")

            # å¤„ç†å¥—è£…æ•ˆæœç­›é€‰é€»è¾‘
            exclude_suit_effect = []
            require_high_value_suits = False

            # ä½¿ç”¨é¢„å®šä¹‰çš„é«˜ä»·å€¼å¥—è£…å’Œç²¾ç¡®ç­›é€‰å¥—è£…
            high_value_suits = HIGH_VALUE_SUITS
            precise_filter_suits = PRECISE_FILTER_SUITS

            # æ£€æŸ¥ç›®æ ‡è£…å¤‡çš„å¥—è£…ç±»å‹
            target_has_high_value_suits = False
            target_has_precise_filter_suits = False

            # å¤„ç†suit_effectï¼šå°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œå¦‚æœå¤±è´¥åˆ™ä¿æŒåŸå€¼
            suit_effect_value = None
            if suit_effect:
                try:
                    suit_effect_value = int(suit_effect)
                except (ValueError, TypeError):
                    # è½¬æ¢å¤±è´¥ï¼ˆå¯èƒ½æ˜¯pet_equipçš„å­—ç¬¦ä¸²å¥—è£…ï¼‰ï¼Œä¿æŒåŸå€¼
                    suit_effect_value = suit_effect

            if suit_effect_value:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é«˜ä»·å€¼å¥—è£…ï¼ˆåªå¯¹æ•°å­—å¥—è£…æœ‰æ•ˆï¼‰
                if isinstance(suit_effect_value, int) and suit_effect_value in high_value_suits:
                    target_has_high_value_suits = True
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç²¾ç¡®ç­›é€‰å¥—è£…ï¼ˆåªå¯¹æ•°å­—å¥—è£…æœ‰æ•ˆï¼‰TODO: éœ€è¦ä¼˜åŒ–éœ€è¦ä¼˜åŒ–éœ€è¦ä¼˜åŒ–éœ€è¦ä¼˜åŒ–éœ€è¦ä¼˜åŒ–éœ€è¦ä¼˜åŒ–éœ€è¦ä¼˜åŒ–
                elif isinstance(suit_effect_value, int) and suit_effect_value in precise_filter_suits:
                    target_has_precise_filter_suits = True

            # å¥—è£…ç­›é€‰é€»è¾‘
            if target_has_high_value_suits:
                # æƒ…å†µ1ï¼šç›®æ ‡è£…å¤‡æœ‰é«˜ä»·å€¼å¥—è£… â†’ å¼ºåˆ¶åªæœç´¢é«˜ä»·å€¼å¥—è£…è£…å¤‡
                require_high_value_suits = True
                print(f"ç›®æ ‡è£…å¤‡åŒ…å«é«˜ä»·å€¼å¥—è£… {suit_effect}ï¼Œå¼ºåˆ¶åªæœç´¢é«˜ä»·å€¼å¥—è£…è£…å¤‡")
            elif target_has_precise_filter_suits:
                # æƒ…å†µ2ï¼šç›®æ ‡è£…å¤‡æœ‰ç²¾ç¡®ç­›é€‰å¥—è£… â†’ ç²¾ç¡®ç­›é€‰è¯¥å¥—è£…è£…å¤‡ï¼Œæ’é™¤å…¶ä»–é«˜ä»·å€¼å¥—è£…
                exclude_suit_effect = high_value_suits + \
                    [s for s in precise_filter_suits if s != suit_effect_value]
                print(f"ç›®æ ‡è£…å¤‡åŒ…å«ç²¾ç¡®ç­›é€‰å¥—è£… {suit_effect}ï¼Œå°†ç²¾ç¡®ç­›é€‰è¯¥å¥—è£…ï¼Œæ’é™¤å…¶ä»–ç²¾ç¡®ç­›é€‰å¥—è£…å’Œé«˜ä»·å€¼å¥—è£…")
            else:
                # æƒ…å†µ3ï¼šç›®æ ‡è£…å¤‡æ²¡æœ‰å¥—è£…æˆ–æœ‰å…¶ä»–å¥—è£… â†’ æ’é™¤é«˜ä»·å€¼å¥—è£…å’Œç²¾ç¡®ç­›é€‰å¥—è£…
                exclude_suit_effect = high_value_suits + precise_filter_suits
                print(f"ç›®æ ‡è£…å¤‡ä¸åŒ…å«é«˜ä»·å€¼å¥—è£…å’Œç²¾ç¡®ç­›é€‰å¥—è£…ï¼Œå°†æ’é™¤è¿™äº›å¥—è£…çš„è£…å¤‡")

            # ç‰¹æŠ€ç­›é€‰é€»è¾‘
            exclude_high_value_special_skills = False
            if require_high_value_suits or (special_effect and len(special_effect) > 0 and not target_has_high_value_effects):
                # å¦‚æœå¼ºåˆ¶é«˜ä»·å€¼å¥—è£…ï¼Œæˆ–è€…æœ‰ç‰¹æ•ˆä½†ä¸æ˜¯é«˜ä»·å€¼ç‰¹æ•ˆï¼Œåˆ™æ£€æŸ¥ç‰¹æŠ€
                if special_skill and special_skill in LOW_VALUE_SPECIAL_SKILLS:
                    # å¦‚æœç›®æ ‡è£…å¤‡æ˜¯ä½ä»·å€¼ç‰¹æŠ€ï¼Œåˆ™åªèƒ½æœç´¢æ— ç‰¹æŠ€æˆ–ä½ä»·å€¼ç‰¹æŠ€çš„è£…å¤‡
                    exclude_high_value_special_skills = True
                    print(f"ç›®æ ‡è£…å¤‡æ˜¯ä½ä»·å€¼ç‰¹æŠ€ {special_skill}ï¼Œå°†æ’é™¤é«˜ä»·å€¼ç‰¹æŠ€è£…å¤‡")

            print(
                f"ç›¸ä¼¼åº¦ç­›é€‰ - é‡è¦ç‰¹æ•ˆ: {filtered_special_effect}, æ’é™¤ç‰¹æ•ˆ: {exclude_special_effect}")
            print(
                f"ç›¸ä¼¼åº¦ç­›é€‰ - æ’é™¤å¥—è£…: {exclude_suit_effect}, å¼ºåˆ¶é«˜ä»·å€¼å¥—è£…: {require_high_value_suits}")

            # å±æ€§ç‚¹åŠ æˆåˆ†ç±»ï¼Œå±æ€§ç‚¹åŠ æˆç±»å‹ä¸€èˆ¬æˆå¯¹å‡ºç°ï¼›æœ‰ä¸‰ç§æƒ…å†µ:1ã€ç©ºç™½ï¼Œå³æ²¡æœ‰å±æ€§ç‚¹ï¼›2ã€ä¸€ä¸ªå±æ€§åŠ æˆï¼ˆæ­£/è´Ÿï¼‰ï¼›3ã€ä¸€å¯¹å±æ€§åŠ æˆï¼ˆä¸¤ä¸ªæ­£æ•°ï¼Œæˆ–è€…ä¸€æ­£ä¸€è´Ÿï¼‰ï¼›
            # å¦‚æœä¸¤ä¸ªéƒ½æ˜¯æ­£æ•°åˆ™æ˜¯ç»„åˆåŒåŠ ï¼Œå¦‚ä½“è´¨+10å’Œè€åŠ›+10éƒ½æ˜¯æ­£æ•°åˆ™æ˜¯ä½“è€ï¼›
            # å¦‚æœå•ç§å±æ€§æ­£æ•°ï¼Œå¦‚ä½“è´¨+10ï¼Œåˆ™æ˜¯ä½“è´¨ï¼›
            # å¦‚æœä¸€ä¸ªæ­£æ•°ä¸€ä¸ªè´Ÿæ•°ï¼Œå¦‚ä½“è´¨+15ï¼Œæ•æ·-2ï¼Œåˆ™æ˜¯ä½“è´¨ï¼›
            # åˆ†å››ä¸ªèšç±»
            # 1."ä½“è´¨", "ä½“è€",
            # 2."é­”åŠ›", "é­”ä½“","é­”è€","é­”æ•",
            # 3."è€åŠ›",
            # 4."æ•æ·","æ•ä½“","æ•è€",
            # 5."åŠ›é‡", "åŠ›ä½“","åŠ›é­”","åŠ›è€","åŠ›æ•"

            # è°ƒç”¨åŸºç¡€æ•°æ®è·å–æ–¹æ³•ï¼ˆåº”ç”¨ä¸šåŠ¡è§„åˆ™ï¼‰
            market_data = self.get_market_data_with_business_rules(
                target_features=target_features,
                special_effect=filtered_special_effect,
                exclude_special_effect=exclude_special_effect,
                exclude_suit_effect=exclude_suit_effect if exclude_suit_effect else None,
                exclude_high_value_simple_equips=exclude_high_value_simple_equips,
                require_high_value_suits=require_high_value_suits,
                exclude_high_value_special_skills=exclude_high_value_special_skills,
                limit=2000  # ç›¸ä¼¼åº¦è®¡ç®—éœ€è¦æ›´å¤šæ•°æ®
            )

            return market_data

        except Exception as e:
            self.logger.error(f"è·å–ç›¸ä¼¼åº¦è®¡ç®—å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def refresh_full_cache(self) -> bool:
        """æ‰‹åŠ¨åˆ·æ–°å…¨é‡ç¼“å­˜"""
        print("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°è£…å¤‡å…¨é‡ç¼“å­˜...")
        self._full_data_cache = None  # æ¸…ç©ºå†…å­˜ç¼“å­˜
        return self._load_full_data_to_redis(force_refresh=True)
    
    def set_cache_expiry(self, hours: int):
        """
        è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´
        
        Args:
            hours: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆå°æ—¶ï¼‰ï¼Œ-1è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
        """
        self._cache_ttl_hours = hours
        if hours == -1:
            print("è£…å¤‡ç¼“å­˜è®¾ç½®ä¸ºæ°¸ä¸è¿‡æœŸæ¨¡å¼ï¼ˆä»…æ‰‹åŠ¨åˆ·æ–°ï¼‰")
        else:
            print(f"è£…å¤‡ç¼“å­˜è®¾ç½®ä¸º {hours} å°æ—¶è‡ªåŠ¨è¿‡æœŸ")
    
    def manual_refresh(self) -> bool:
        """
        æ‰‹åŠ¨åˆ·æ–°ç¼“å­˜ï¼ˆæ˜¾å¼è°ƒç”¨ï¼‰
        """
        print("ğŸ“± ç”¨æˆ·æ‰‹åŠ¨åˆ·æ–°è£…å¤‡ç¼“å­˜")
        return self.refresh_full_cache()

    def get_cache_status(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯"""
        try:
            status = {
                'redis_available': False,
                'full_cache_exists': False,
                'full_cache_size': 0,
                'memory_cache_size': 0,
                'cache_key': self._full_cache_key,
                'cache_ttl_hours': self._cache_ttl_hours,
                'cache_never_expires': self._cache_ttl_hours == -1,
                'refresh_mode': 'manual_only' if self._cache_ttl_hours == -1 else 'auto_expire'
            }
            
            if self.redis_cache and self.redis_cache.is_available():
                status['redis_available'] = True
                
                # æ£€æŸ¥Redisä¸­çš„å…¨é‡ç¼“å­˜
                try:
                    metadata = self.redis_cache.get(f"{self._full_cache_key}:meta")
                    if metadata:
                        status['full_cache_exists'] = True
                        status['full_cache_size'] = metadata.get('total_rows', 0)
                        status['cache_created_at'] = metadata.get('created_at')
                        status['chunk_info'] = {
                            'total_chunks': metadata.get('total_chunks', 0),
                            'chunk_size': metadata.get('chunk_size', 0)
                        }
                except Exception as e:
                    self.logger.debug(f"æ£€æŸ¥Redisç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            
            # æ£€æŸ¥å†…å­˜ç¼“å­˜
            if self._full_data_cache is not None:
                status['memory_cache_size'] = len(self._full_data_cache)
            
            return status
            
        except Exception as e:
            self.logger.error(f"è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            return {'error': str(e)}

    def get_refresh_status(self) -> Dict[str, Any]:
        """
        è·å–åˆ·æ–°è¿›åº¦çŠ¶æ€
        
        Returns:
            Dict: åŒ…å«è¿›åº¦ä¿¡æ¯çš„å­—å…¸
        """
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” è·å–åˆ·æ–°çŠ¶æ€ - å®ä¾‹ID: {id(self)}")
        print(f"ğŸ” å½“å‰çŠ¶æ€: {self._refresh_status}, è¿›åº¦: {self._refresh_progress}%")
        print(f"ğŸ” å†…å­˜ç¼“å­˜çŠ¶æ€: {self._full_data_cache is not None and not self._full_data_cache.empty if self._full_data_cache is not None else False}")
        
        status_info = {
            "status": self._refresh_status,
            "progress": self._refresh_progress,
            "message": self._refresh_message,
            "processed_records": self._refresh_processed_records,
            "total_records": self._refresh_total_records,
            "current_batch": self._refresh_current_batch,
            "total_batches": self._refresh_total_batches,
            "start_time": self._refresh_start_time.isoformat() if self._refresh_start_time else None,
            "elapsed_seconds": int((datetime.now() - self._refresh_start_time).total_seconds()) if self._refresh_start_time else 0
        }
        
        return status_info

    @classmethod
    def clear_cache(cls):
        """æ¸…ç©ºå•ä¾‹å®ä¾‹çš„ç¼“å­˜"""
        with cls._lock:
            if cls._instance and hasattr(cls._instance, '_full_data_cache'):
                cls._instance._full_data_cache = None
                cls._instance._refresh_status = "idle"
                cls._instance._refresh_progress = 0
                cls._instance._refresh_message = ""
                print("å·²æ¸…ç©ºè£…å¤‡æ•°æ®ç¼“å­˜")

    @classmethod
    def get_cache_status_static(cls) -> Dict[str, Any]:
        """è·å–å•ä¾‹å®ä¾‹çš„ç¼“å­˜çŠ¶æ€"""
        with cls._lock:
            if cls._instance:
                return cls._instance.get_cache_status()
            else:
                return {
                    'redis_available': False,
                    'full_cache_exists': False,
                    'full_cache_size': 0,
                    'memory_cache_size': 0
                }

    @classmethod
    def get_refresh_status_static(cls) -> Dict[str, Any]:
        """è·å–å•ä¾‹å®ä¾‹çš„åˆ·æ–°çŠ¶æ€"""
        with cls._lock:
            if cls._instance:
                return cls._instance.get_refresh_status()
            else:
                return {
                    "status": "idle",
                    "progress": 0,
                    "message": "",
                    "processed_records": 0,
                    "total_records": 0,
                    "current_batch": 0,
                    "total_batches": 0,
                    "start_time": None,
                    "elapsed_seconds": 0
                }

    def _should_filter_suit_effect(self, suit_effect: Union[int, str]) -> bool:
        """
        åˆ¤æ–­å¥—è£…æ•ˆæœæ˜¯å¦åº”è¯¥è¢«ç”¨äºç­›é€‰

        ä¸šåŠ¡è§„åˆ™ï¼šåªæœ‰ç‰¹å®šçš„é«˜ä»·å€¼å¥—è£…æ•ˆæœæ‰ç”¨äºç²¾ç¡®ç­›é€‰ï¼Œ
        å…¶ä»–å¥—è£…æ•ˆæœåœ¨ç›¸ä¼¼åº¦è®¡ç®—æ—¶è¿›è¡Œèšç±»å¤„ç†

        Args:
            suit_effect: å¥—è£…æ•ˆæœIDï¼ˆæ•°å­—æˆ–æ•°å­—å­—ç¬¦ä¸²ï¼Œpet_equipå¯èƒ½æ˜¯çº¯å­—ç¬¦ä¸²ï¼‰

        Returns:
            bool: æ˜¯å¦åº”è¯¥ç­›é€‰æ­¤å¥—è£…æ•ˆæœ
        """
        # å…è®¸ç²¾ç¡®ç­›é€‰çš„å¥—è£…æ•ˆæœï¼šå®šå¿ƒæœ¯ã€å˜èº«æœ¯ã€ç¢æ˜Ÿè¯€ã€å¤©ç¥æŠ¤ä½“ã€æ»¡å¤©èŠ±é›¨ã€æµªæ¶Œ
        allowed_suit_effects = PRECISE_FILTER_SUITS

        # å°è¯•è½¬æ¢ä¸ºæ•°å­—è¿›è¡Œæ¯”è¾ƒ
        try:
            suit_effect_num = int(suit_effect)
            return suit_effect_num in allowed_suit_effects
        except (ValueError, TypeError):
            # è½¬æ¢å¤±è´¥ï¼ˆå¯èƒ½æ˜¯pet_equipçš„å­—ç¬¦ä¸²å¥—è£…ï¼‰ï¼Œä¸è¿›è¡Œç²¾ç¡®ç­›é€‰
            return False

    def get_market_data_with_business_rules(self,
                                            target_features: Dict[str, Any],
                                            **kwargs) -> pd.DataFrame:
        """
        åº”ç”¨ä¸šåŠ¡è§„åˆ™è·å–å¸‚åœºæ•°æ®

        è¿™ä¸ªæ–¹æ³•åœ¨åŸºç¡€æŸ¥è¯¢çš„åŸºç¡€ä¸Šåº”ç”¨ç‰¹å®šçš„ä¸šåŠ¡è§„åˆ™ï¼Œ
        æ¯”å¦‚å¥—è£…æ•ˆæœçš„ç­›é€‰ç­–ç•¥ç­‰

        Args:
            target_features: ç›®æ ‡è£…å¤‡ç‰¹å¾
            **kwargs: å…¶ä»–æŸ¥è¯¢å‚æ•°

        Returns:
            å¸‚åœºæ•°æ®DataFrame
        """
        try:
            # å¤„ç†å¥—è£…æ•ˆæœä¸šåŠ¡è§„åˆ™
            suit_effect = target_features.get('suit_effect', 0)
            filtered_suit_effect = None

            if suit_effect and self._should_filter_suit_effect(suit_effect):
                filtered_suit_effect = suit_effect
                print(f"å¥—è£…æ•ˆæœ {suit_effect} å°†ç”¨äºç²¾ç¡®ç­›é€‰")
            else:
                print(f"å¥—è£…æ•ˆæœ {suit_effect} å°†åœ¨ç›¸ä¼¼åº¦è®¡ç®—æ—¶å¤„ç†")

            # åˆå¹¶å‚æ•°
            query_params = {
                'kindid': target_features.get('kindid'),
                'level_range': target_features.get('equip_level_range'),
                'special_skill': target_features.get('special_skill', 0),
                'suit_effect': filtered_suit_effect,
                **kwargs
            }

            return self.get_market_data(**query_params)

        except Exception as e:
            self.logger.error(f"åº”ç”¨ä¸šåŠ¡è§„åˆ™è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def _classify_addon_attributes(self, addon_minjie: int = 0, addon_liliang: int = 0,
                                   addon_naili: int = 0, addon_tizhi: int = 0,
                                   addon_moli: int = 0) -> str:
        """
        æ ¹æ®è£…å¤‡çš„é™„åŠ å±æ€§åˆ†ç±»
        #å±æ€§ç‚¹åŠ æˆåˆ†ç±»ï¼Œå±æ€§ç‚¹åŠ æˆç±»å‹ä¸€èˆ¬æˆå¯¹å‡ºç°ï¼›
        # å¦‚æœä¸¤ä¸ªéƒ½æ˜¯æ­£æ•°åˆ™æ˜¯ç»„åˆåŒåŠ ï¼Œå¦‚ä½“è´¨+10å’Œè€åŠ›+10éƒ½æ˜¯æ­£æ•°åˆ™æ˜¯ä½“è€ï¼›
        # å¦‚æœå•ç§å±æ€§æ­£æ•°ï¼Œå¦‚ä½“è´¨+10ï¼Œåˆ™æ˜¯ä½“è´¨ï¼›
        # å¦‚æœä¸€ä¸ªæ­£æ•°ä¸€ä¸ªè´Ÿæ•°ï¼Œå¦‚ä½“è´¨+15ï¼Œæ•æ·-2ï¼Œåˆ™æ˜¯ä½“è´¨ï¼›
        # åˆ†å››ä¸ªèšç±»
        # 1."ä½“è´¨", "ä½“è€",
        # 2."é­”åŠ›", "é­”ä½“","é­”è€","é­”æ•",
        # 3."è€åŠ›",
        # 4."æ•æ·","æ•ä½“","æ•è€",
        # 5."åŠ›é‡", "åŠ›ä½“","åŠ›é­”","åŠ›è€","åŠ›æ•"

        Args:
            addon_minjie: æ•æ·åŠ æˆ
            addon_liliang: åŠ›é‡åŠ æˆ
            addon_naili: è€åŠ›åŠ æˆ
            addon_tizhi: ä½“è´¨åŠ æˆ
            addon_moli: é­”åŠ›åŠ æˆ

        Returns:
            str: å±æ€§åˆ†ç±»ç±»å‹
        """
        # ç»Ÿè®¡æ­£æ•°å±æ€§
        positive_attrs = {}
        if addon_minjie > 0:
            positive_attrs['æ•æ·'] = addon_minjie
        if addon_liliang > 0:
            positive_attrs['åŠ›é‡'] = addon_liliang
        if addon_naili > 0:
            positive_attrs['è€åŠ›'] = addon_naili
        if addon_tizhi > 0:
            positive_attrs['ä½“è´¨'] = addon_tizhi
        if addon_moli > 0:
            positive_attrs['é­”åŠ›'] = addon_moli

        # å¦‚æœæ²¡æœ‰æ­£æ•°å±æ€§
        if not positive_attrs:
            return "æ— å±æ€§"

        # å¦‚æœåªæœ‰ä¸€ä¸ªæ­£æ•°å±æ€§
        if len(positive_attrs) == 1:
            attr_name = list(positive_attrs.keys())[0]
            return attr_name

        # å¦‚æœæœ‰ä¸¤ä¸ªæ­£æ•°å±æ€§ï¼ŒæŒ‰ç»„åˆè§„åˆ™åˆ†ç±»
        if len(positive_attrs) == 2:
            attr_names = sorted(positive_attrs.keys())

            # ä½“è´¨ç›¸å…³ç»„åˆ
            if 'ä½“è´¨' in attr_names and 'è€åŠ›' in attr_names:
                return "ä½“è€"
            elif 'ä½“è´¨' in attr_names and 'æ•æ·' in attr_names:
                return "æ•ä½“"
            elif 'ä½“è´¨' in attr_names and 'åŠ›é‡' in attr_names:
                return "åŠ›ä½“"
            elif 'ä½“è´¨' in attr_names and 'é­”åŠ›' in attr_names:
                return "é­”ä½“"

            # é­”åŠ›ç›¸å…³ç»„åˆ
            elif 'é­”åŠ›' in attr_names and 'è€åŠ›' in attr_names:
                return "é­”è€"
            elif 'é­”åŠ›' in attr_names and 'æ•æ·' in attr_names:
                return "é­”æ•"
            elif 'é­”åŠ›' in attr_names and 'åŠ›é‡' in attr_names:
                return "åŠ›é­”"

            # æ•æ·ç›¸å…³ç»„åˆ
            elif 'æ•æ·' in attr_names and 'è€åŠ›' in attr_names:
                return "æ•è€"
            elif 'æ•æ·' in attr_names and 'åŠ›é‡' in attr_names:
                return "åŠ›æ•"

            # åŠ›é‡è€åŠ›ç»„åˆ
            elif 'åŠ›é‡' in attr_names and 'è€åŠ›' in attr_names:
                return "åŠ›è€"

        # å¤šäºä¸¤ä¸ªå±æ€§æˆ–å…¶ä»–æƒ…å†µï¼Œè¿”å›ä¸»å±æ€§ï¼ˆæ•°å€¼æœ€å¤§çš„ï¼‰
        if positive_attrs:
            main_attr = max(positive_attrs.items(), key=lambda x: x[1])[0]
            return main_attr

        return "æ— å±æ€§"

    def _get_target_addon_classification(self, target_features: Dict[str, Any]) -> str:
        """
        è·å–ç›®æ ‡è£…å¤‡çš„å±æ€§åˆ†ç±»

        Args:
            target_features: ç›®æ ‡è£…å¤‡ç‰¹å¾

        Returns:
            str: å±æ€§åˆ†ç±»ç±»å‹
        """
        addon_minjie = target_features.get('addon_minjie', 0)
        addon_liliang = target_features.get('addon_liliang', 0)
        addon_naili = target_features.get('addon_naili', 0)
        addon_tizhi = target_features.get('addon_tizhi', 0)
        addon_moli = target_features.get('addon_moli', 0)

        return self._classify_addon_attributes(
            addon_minjie, addon_liliang, addon_naili, addon_tizhi, addon_moli
        )

    def get_market_data_with_addon_classification(self,
                                                  target_features: Dict[str, Any],
                                                  **kwargs) -> pd.DataFrame:
        """
        æ ¹æ®å±æ€§åŠ æˆåˆ†ç±»è·å–å¸‚åœºæ•°æ®

        è‡ªåŠ¨æŒ‰ç…§è£…å¤‡å±æ€§åˆ†ç±»è¿‡æ»¤å¸‚åœºæ•°æ®ï¼Œåªä¿ç•™åŒç±»å±æ€§è£…å¤‡

        Args:
            target_features: ç›®æ ‡è£…å¤‡ç‰¹å¾
            **kwargs: å…¶ä»–æŸ¥è¯¢å‚æ•°

        Returns:
            å¸‚åœºæ•°æ®DataFrameï¼ŒåŒ…å«å±æ€§åˆ†ç±»ä¿¡æ¯ï¼Œå·²æŒ‰åŒç±»å±æ€§è¿‡æ»¤
        """
        try:
            # è·å–åŸºç¡€å¸‚åœºæ•°æ®
            market_data = self.get_market_data_for_similarity(target_features)
            if market_data.empty:
                return market_data

            # è·å–ç›®æ ‡è£…å¤‡çš„å±æ€§åˆ†ç±»
            target_classification = self._get_target_addon_classification(
                target_features)
            print(f"ç›®æ ‡è£…å¤‡å±æ€§åˆ†ç±»: {target_classification}")

            # ä¸ºå¸‚åœºæ•°æ®æ·»åŠ å±æ€§åˆ†ç±»
            market_data['addon_classification'] = market_data.apply(
                lambda row: self._classify_addon_attributes(
                    row.get('addon_minjie', 0),
                    row.get('addon_liliang', 0),
                    row.get('addon_naili', 0),
                    row.get('addon_tizhi', 0),
                    row.get('addon_moli', 0)
                ), axis=1
            )

            # å§‹ç»ˆæŒ‰å±æ€§åˆ†ç±»è¿‡æ»¤ï¼ˆé™¤éç›®æ ‡è£…å¤‡æ˜¯æ— å±æ€§ï¼‰
            if target_classification != "æ— å±æ€§":
                # å®šä¹‰åŒç±»å±æ€§åˆ†ç»„
                classification_groups = {
                    "ä½“è´¨ç³»": ["ä½“è´¨", "ä½“è€"],
                    "é­”åŠ›ç³»": ["é­”åŠ›", "é­”ä½“", "é­”è€", "é­”æ•"],
                    "è€åŠ›ç³»": ["è€åŠ›"],
                    "æ•æ·ç³»": ["æ•æ·", "æ•ä½“", "æ•è€"],
                    "åŠ›é‡ç³»": ["åŠ›é‡", "åŠ›ä½“", "åŠ›é­”", "åŠ›è€", "åŠ›æ•"]
                }

                # æ‰¾åˆ°ç›®æ ‡è£…å¤‡æ‰€å±çš„åˆ†ç»„
                target_group = None
                for group_name, classifications in classification_groups.items():
                    if target_classification in classifications:
                        target_group = classifications
                        break

                if target_group:
                    # è¿‡æ»¤åŒç±»å±æ€§è£…å¤‡ï¼ˆä¿ç•™æ— å±æ€§è£…å¤‡ä½œä¸ºå‚è€ƒï¼‰
                    before_filter_count = len(market_data)
                    market_data = market_data[
                        (market_data['addon_classification'].isin(target_group)) |
                        (market_data['addon_classification'] == "æ— å±æ€§")
                    ]
                    after_filter_count = len(market_data)

                    print(
                        f"å±æ€§åˆ†ç±»è¿‡æ»¤: {target_classification} -> åŒç±»å±æ€§ {target_group}")
                    print(
                        f"è¿‡æ»¤ç»“æœ: {before_filter_count} -> {after_filter_count} æ¡æ•°æ®")
                else:
                    print(f"æœªæ‰¾åˆ°å±æ€§åˆ†ç±» {target_classification} å¯¹åº”çš„åˆ†ç»„ï¼Œä¸è¿›è¡Œè¿‡æ»¤")
            else:
                print(f"ç›®æ ‡è£…å¤‡æ— å±æ€§ï¼Œä¸è¿›è¡Œå±æ€§åˆ†ç±»è¿‡æ»¤")

            return market_data

        except Exception as e:
            self.logger.error(f"æŒ‰å±æ€§åˆ†ç±»è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
